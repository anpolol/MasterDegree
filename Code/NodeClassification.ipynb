{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-gN3S4NhAjs",
    "outputId": "fef06879-cb42-4f09-db2d-88671e8c4315"
   },
   "outputs": [],
   "source": [
    "#!pip install -q torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 21 19:23:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 207... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   57C    P2    64W / 215W |   1037MiB /  8192MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       988    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      1384    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      1424    C+G   ...kyb3d8bbwe\\HxAccounts.exe    N/A      |\n",
      "|    0   N/A  N/A      1744    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A      2068    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      2232    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A      2464    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3096    C+G   ...es.TextInput.InputApp.exe    N/A      |\n",
      "|    0   N/A  N/A      4828    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      7796    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
      "|    0   N/A  N/A     10796    C+G   ...3d8bbwe\\MicrosoftEdge.exe    N/A      |\n",
      "|    0   N/A  N/A     11868    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     13124    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     13224      C   ...ython\\Python37\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     13488    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -q --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install -q --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install -q --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install -q --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "from modules.model import Net\n",
    "from sklearn.metrics import precision_score\n",
    "from datetime import datetime\n",
    "from modules.sampling import Sampler, SamplerContextMatrix, SamplerRandomWalk\n",
    "from datetime import datetime\n",
    "from torch_geometric.data import GraphSAINTRandomWalkSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "class Main():\n",
    "    def __init__(self,conv, device, loss_function, mode = 'unsupervised',**kwargs):\n",
    "        self.dataset =Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())\n",
    "        data = self.dataset[0]\n",
    "        self.Conv = conv\n",
    "        self.device = device# if torch.cuda.is_available() else 'cpu')\n",
    "        self.x = data.x#.to(device)\n",
    "        self.y = data.y.squeeze()#.to(device)\n",
    "        self.data=data.to(device)\n",
    "        self.loss = loss_function\n",
    "        self.mode = mode\n",
    "        self.train_mask = torch.tensor([True]*int(0.8*len(data.x)+1) + [False]*int(0.2*len(data.x)))\n",
    "        #val_mask = torch.tensor([False]*int(0.6*len(data.x)+1) + [True]*int(0.2*len(data.x)+1)+[False]*int(0.2*len(data.x)))\n",
    "        self.test_mask = torch.tensor([False]*int(0.8*len(data.x)+1) + [True]*int(0.2*len(data.x)))\n",
    "        self.flag = self.loss[\"flag\"]\n",
    "        \n",
    "      #  if self.flag:\n",
    "       #     name_of_file = \"samples_\"+self.loss[\"Name\"]+\".pickle\"\n",
    "        #    if os.path.exists(name_of_file):\n",
    "         #       with open(name_of_file,'rb') as f:\n",
    "          #          self.samples = pickle.load(f)\n",
    "           # else:\n",
    "            #    arr=torch.nonzero(self.train_mask == True)\n",
    "             #   indices_of_train_data = ([item for sublist in arr for item in sublist])\n",
    "              #  self.samples = self.LossSampler.sample(indices_of_train_data,alpha = self.alpha)\n",
    "\n",
    "        super(Main, self).__init__()\n",
    "    \n",
    "    def train(self, model,data,optimizer,Sampler,train_loader,dropout,epoch,**kwargs):\n",
    "        model.train()   \n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        if model.mode == 'unsupervised':\n",
    "            if model.conv=='GCN':\n",
    "                arr=torch.nonzero(self.train_mask == True)\n",
    "                indices_of_train_data = ([item for sublist in arr for item in sublist])\n",
    "                d_out = datetime.now()\n",
    "                out = model.inference(data.to(device),dp=dropout)\n",
    "                #print('свертка посчиталась за: ',datetime.now() - d_out)\n",
    "                d_samples=datetime.now()\n",
    "                if (self.flag and epoch == 0) or not self.flag:\n",
    "                    name_of_file = \"samples_\"+self.loss[\"Name\"]+\".pickle\"\n",
    "                    #self.samples = Sampler.sample(indices_of_train_data) \n",
    "                    \n",
    "                    if os.path.exists(name_of_file):\n",
    "                        with open(name_of_file,'rb') as f:\n",
    "                            self.samples = pickle.load(f)\n",
    "                    else:\n",
    "                        arr=torch.nonzero(self.train_mask == True)\n",
    "                        indices_of_train_data = ([item for sublist in arr for item in sublist])\n",
    "                        self.samples = Sampler.sample(indices_of_train_data)\n",
    "                        with open(name_of_file,'wb') as f:\n",
    "                            self.samples = pickle.dump(self.samples,f)\n",
    "\n",
    "                #print('сэмплирование соседей для ф.п./матрица similarity: ', datetime.now()-d_samples)\n",
    "\n",
    "                d_loss = datetime.now()\n",
    "                loss = model.loss(out[self.train_mask], self.samples)\n",
    "                #print('подсчет функции потерь: ', datetime.now()-d_loss)\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    if len(train_loader.sizes) == 1:\n",
    "                        adjs = [adjs]\n",
    "                    # adjs holds a list of (edge_index, e_id, size) tuples.\n",
    "                    adjs = [adj.to(device) for adj in adjs]\n",
    "                    d_out = datetime.now()\n",
    "                    out = model.forward(data.x[n_id.to(device)].to(device), adjs)\n",
    "                   # print('свертка (на батче) посчиталась за: ',datetime.now() - d_out)\n",
    "                    d_samples=datetime.now()\n",
    "                    if (self.flag and epoch == 0) or not self.flag:\n",
    "                        self.samples = Sampler.sample(n_id[:batch_size]) \n",
    "\n",
    "                                          \n",
    "                    #print('сэмплирование соседей для ф.п./матрица similarity: ', datetime.now()-d_samples)\n",
    "                    d_loss = datetime.now()\n",
    "                    loss = model.loss(out, self.samples)#pos_batch.to(device), neg_batch.to(device))\n",
    "                    #print('подсчет функции потерь: ', datetime.now()-d_loss)\n",
    "                    total_loss+=loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()      \n",
    "            return total_loss /len(train_loader)\n",
    "        elif model.mode== 'supervised':\n",
    "            if model.conv=='GCN':\n",
    "                out = model.inference(data.to(device),dp=dropout)\n",
    "                loss = model.loss_sup(out[self.train_mask],y[self.train_mask])\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    adjs = [adj for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id].to(device), adjs)\n",
    "                    loss = model.loss_sup(out,y[n_id[:batch_size]])\n",
    "                    total_loss+=loss\n",
    "            total_loss.backward(retain_graph=True)\n",
    "            optimizer.step()      \n",
    "            return total_loss /len(train_loader)       \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, model,data,classifier,**kwargs):#,n_estimators,learning_rate_carboost, max_depth): \n",
    "        model.eval()\n",
    "        out = model.inference(data.to(device))\n",
    "        y_true = self.y.detach().numpy()\n",
    "        if model.mode == 'supervised':\n",
    "            y_true = self.y.unsqueeze(-1)\n",
    "            y_pred = out.cpu().argmax(dim=-1, keepdim=True)\n",
    "            accs = []\n",
    "            for mask in [self.train_mask, self.val_mask, self.test_mask]:    \n",
    "                accs+=[int(y_pred[mask].eq(y_true[mask]).sum()) / int(mask.sum())]\n",
    "            return accs\n",
    "        elif model.mode == 'unsupervised': \n",
    "            if classifier == 'logistic regression':\n",
    "                clf = LogisticRegressionCV(cv = 5, max_iter = 3000).fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\n",
    "            else:\n",
    "                n_estimators= kwargs[\"n_estimators\"]\n",
    "                learning_rate_catboost = kwargs[\"learning_rate_catboost\"]\n",
    "                max_depth = kwargs[\"max_depth\"]\n",
    "                clf = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate = learning_rate_catboost, max_depth=max_depth, random_state=0)\n",
    "                clf.fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\n",
    "            accs = []\n",
    "            for mask in [self.train_mask, self.test_mask]:    \n",
    "                accs += [(clf.score(out.cpu().detach()[mask].numpy(), self.y.detach()[mask].cpu().numpy()))]\n",
    "            return accs\n",
    "            \n",
    "\n",
    "    def run(self,**kwargs):\n",
    "        \n",
    "        hidden_layer = 64\n",
    "        out_layer = 128\n",
    "        dropout = 0.4\n",
    "        size = 1\n",
    "        learning_rate = 0.001\n",
    "\n",
    "        classifier = \"logistic regression\"\n",
    "        train_loader = NeighborSampler(self.data.edge_index, node_idx=self.train_mask, batch_size = int(sum(self.train_mask)), sizes=[-1]*size)\n",
    "        LossSampler = Sampler(self.data,device=device,mask=self.train_mask,loss_info=self.loss)\n",
    "        model = Net(dataset = self.dataset,mode=self.mode,conv=self.Conv,loss_function=self.loss,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = (size),dropout = dropout)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)\n",
    "                #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
    "        scheduler=lr_scheduler.StepLR(optimizer, step_size=25,gamma=0.1)\n",
    "        losses=[]\n",
    "        train_accs=[]\n",
    "        test_accs=[]\n",
    "        val_accs=[]\n",
    "        name_of_plot='conv: '+model.conv+', mode: '+model.mode+', loss from '+self.loss[\"Name\"]\n",
    "\n",
    "        print(name_of_plot)\n",
    "\n",
    "        for epoch in range(50):\n",
    "                    print('epoch',epoch)\n",
    "                    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,0,0.7, epoch)\n",
    "                    losses.append(loss)\n",
    "                    d_test = datetime.now()\n",
    "                    train_acc, test_acc = self.test(model,self.data,'logistic regression')\n",
    "                   # print('тестирование заняло: ', datetime.now()-d_test)\n",
    "                    train_accs.append(train_acc)\n",
    "                    test_accs.append(test_acc)\n",
    "                   # val_accs.append(val_acc)\n",
    "                    log = 'Loss: {:.4f}, Epoch: {:03d}, Train: {:.4f}, Test: {:.4f}'\n",
    "                    #scheduler.step()\n",
    "                    print(log.format(loss, epoch, train_acc, test_acc))\n",
    "        print('Test acc on the last epoch ', test_acc)\n",
    "        plt.plot(losses)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "        plt.plot(test_accs)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "                    #return [precision_score(y_true[train_mask.cpu()], best_preds_train, average='macro'), precision_score(y_true[val_mask.cpu()], best_preds_val, average='macro'),precision_score(y_true[test_mask.cpu()], best_preds, average='macro')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainOptuna(Main):\n",
    "    def objective(self,trial):\n",
    "        # Integer parameter\n",
    "        hidden_layer = trial.suggest_categorical(\"hidden_layer\", [32,64,128,256])\n",
    "        out_layer = trial.suggest_categorical(\"out_layer\", [32,64,128])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0,0.5,step = 0.1)\n",
    "        size = trial.suggest_categorical(\"size of network, number of convs\", [1,2,3])\n",
    "        Conv = self.Conv# trial.suggest_categorical(\"conv\", [\"SAGE\",\"GCN\",\"GAT\"])\n",
    "\n",
    "        # варьируем параметры\n",
    "        loss_to_train={}\n",
    "        for name in self.loss:\n",
    "            if type(self.loss[name]) == list :\n",
    "                if len(self.loss[name]) == 3:\n",
    "                    var = trial.suggest_int(name,self.loss[name][0],self.loss[name][1],step=self.loss[name][2])\n",
    "                    loss_to_train[name] = var\n",
    "                elif len(self.loss[name]) == 2:\n",
    "                    var_2 = trial.suggest_float(name,self.loss[name][0],self.loss[name][1])\n",
    "                    loss_to_train[name] = var_2\n",
    "            else:\n",
    "                loss_to_train[name] = self.loss[name]\n",
    "        Sampler =loss_to_train[\"Sampler\"]\n",
    "\n",
    "        model = Net(dataset = self.dataset,mode='unsupervised',conv=Conv,loss_function=loss_to_train,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = size,dropout = dropout)\n",
    "\n",
    "        train_loader = NeighborSampler(self.data.edge_index, batch_size =int(sum(self.train_mask)),node_idx=self.train_mask, sizes=[-1]*size)\n",
    "        \n",
    "        #train_loader = GraphSAINTRandomWalkSampler(data, batch_size=2176, walk_length=2,num_steps=5, sample_coverage=100,save_dir=dataset.processed_dir,num_workers=4)\n",
    "\n",
    "        LossSampler = Sampler(self.data,device=self.device,mask=self.train_mask,loss_info=loss_to_train)\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        learning_rate= trial.suggest_float(\"lr\",5e-4,1e-2)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)  \n",
    "\n",
    "        classifier = \"logistic regression\" #trial.suggest_categorical(\"classifier\", [\"logistic regression\", \"catboost\"])\n",
    "\n",
    "        if classifier == \"catboost\":\n",
    "            n_estimators = trial.suggest_int(\"n of estimators\", 10,40,5)\n",
    "            learning_rate_catboost = trial.suggest_float(\"lr_catboost\",5e-4,1e-2)\n",
    "            max_depth = trial.suggest_int(\"max_depth\",1,10,2)\n",
    "        else:\n",
    "            n_estimators = -1\n",
    "            learning_rate_catboost =-1\n",
    "            max_depth = -1\n",
    "        #training of the model\n",
    "        for epoch in range(50):\n",
    "            loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch)\n",
    "\n",
    "        train_acc, test_acc = self.test(model,self.data,classifier,n_estimators=n_estimators,learning_rate_catboost=learning_rate_catboost,max_depth=max_depth)\n",
    "\n",
    "\n",
    "        trial.report(test_acc,epoch)\n",
    "\n",
    "        return test_acc\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "\n",
    "\n",
    "        self.Conv = \"GCN\"\n",
    "        study = optuna.create_study(direction=\"maximize\",study_name=self.loss[\"Name\"]+\" loss, GCN conv\")\n",
    "        study.optimize(self.objective,n_trials = 10)\n",
    "\n",
    "        print('Best trial:')\n",
    "        trial = study.best_trial\n",
    "        print(\" Value: \", trial.value)\n",
    "        print(\" Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\" {}: {}\".format(key,value))\n",
    "        \n",
    "        self.Conv = \"SAGE\"\n",
    "        study = optuna.create_study(direction=\"maximize\",study_name=self.loss[\"Name\"]+\" loss, SAGE conv\")\n",
    "        study.optimize(self.objective,n_trials = 10)\n",
    "\n",
    "        print('Best trial:')\n",
    "        trial = study.best_trial\n",
    "        print(\" Value: \", trial.value)\n",
    "        print(\" Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\" {}: {}\".format(key,value))\n",
    "        \n",
    "        self.Conv = \"GAT\"\n",
    "        study = optuna.create_study(direction=\"maximize\",study_name=self.loss[\"Name\"]+\" loss, GAT conv\")\n",
    "        study.optimize(self.objective,n_trials = 10)\n",
    "\n",
    "        print('Best trial:')\n",
    "        trial = study.best_trial\n",
    "        print(\" Value: \", trial.value)\n",
    "        print(\" Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\" {}: {}\".format(key,value))    \n",
    "            \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " #SAGE = {\"Name\":\"SAGE\" , \"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":20,\"context size\" : [5,20,5],\"p\":1,\"q\":1, \"loss var\": \"Random Walks\",\"flag\":False,\"Sampler\" =SamplerRandomWalk }\n",
    "from modules.sampling import Sampler, SamplerContextMatrix, SamplerRandomWalk,SamplerFactorization\n",
    "DeepWalk = {\"Name\": \"DeepWalk\",\"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":[1,21,5],\"context_size\" : [5,20,5],\"p\":1,\"q\":1,\"loss var\": \"Random Walks\",\"flag\":False,\"Sampler\" : SamplerRandomWalk } #Проблемы с памятью после того, как увеличила количество тренировочных данных\n",
    "Node2Vec = {\"Name\": \"Node2Vec\",\"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":[1,21,5],\"context_size\" : [5,20,5],\"p\": [0.0,0.9] ,\"q\":[0.0,0.9], \"loss var\": \"Random Walks\",\"flag\":False,\"Sampler\": SamplerRandomWalk}#то же самое \n",
    "\n",
    "LINE = {\"Name\": \"LINE\",\"C\": \"Adj\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag\":True,\"Sampler\" :SamplerContextMatrix} \n",
    "HOPE_RPR = {\"Name\": \"HOPE_RPR\",\"C\":\"RPR\",\"loss var\": \"Factorization\",\"flag\":True,\"alpha\": [0,1],\"Sampler\" :SamplerFactorization} #проверить\n",
    "HOPE_Katz = {\"Name\": \"HOPE_Katz\",\"C\":\"Katz\",\"loss var\": \"Factorization\",\"flag\":True,\"betta\": [0,1],\"Sampler\" :SamplerFactorization,} #проверить\n",
    "HOPE_CN = {\"Name\": \"HOPE_CommonNeighbors\",\"C\":\"CN\",\"loss var\": \"Factorization\",\"flag\":True,\"Sampler\" :SamplerFactorization} \n",
    "HOPE_AA = {\"Name\": \"HOPE_AdamicAdar\",\"C\":\"AA\",\"loss var\": \"Factorization\",\"flag\":True,\"Sampler\" :SamplerFactorization} \n",
    "\n",
    "LapEigen = {\"Name\": \"LaplacianEigenMaps\", \"C\":\"Adj\",\"loss var\": \"Laplacian EigenMaps\",\"flag\":True,\"Sampler\" :SamplerFactorization}\n",
    "GraphFactorization = {\"Name\": \"Graph Factorization\",\"C\":\"Adj\",\"loss var\": \"Factorization\",\"flag\":True,\"Sampler\" :SamplerFactorization} \n",
    "VERSE_PPR =  {\"Name\": \"VERSE_PPR\",\"C\": \"PPR\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag\":True,\"Sampler\" :SamplerContextMatrix,\"alpha\": [0,1]}\n",
    "\n",
    "VERSE_SR =  {\"Name\": \"VERSE_SimRank\",\"C\": \"SR\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag\":True,\"Sampler\":SamplerContextMatrix} \n",
    "VERSE_Adj =  {\"Name\": \"VERSE_Adj\",\"C\": \"Adj\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag\":True,\"Sampler\" :SamplerContextMatrix} \n",
    "\n",
    "APP ={}#Implement\n",
    "Struc2Vec ={} #Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-21 19:23:58,204]\u001b[0m A new study created in memory with name: VERSE_SimRank loss, GCN conv\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\MasterDegree\\Code\\modules\\sampling.py:263: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  ind = (prob>c).nonzero()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3100, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:31.050030\n",
      "tensor([0.0000, 0.2600, 0.0000,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:29.701002\n",
      "tensor([0.0000, 0.0000, 0.1700,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:30.523999\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:31.212000\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:31.756023\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.949969\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.811009\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.492967\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:32.096972\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.828001\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:29.549994\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:29.945004\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:31.349971\n",
      "tensor([0.0000, 0.0000, 0.0100,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:31.019033\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.538999\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.398970\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.572030\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.670000\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.168970\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.168030\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.466995\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.117977\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.246030\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.379001\n",
      "tensor([0.0100, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:29.984992\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.463977\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.158023\n",
      "tensor([0.0000, 0.0200, 0.0000,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:29.879004\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.242008\n",
      "tensor([0.0000, 0.0100, 0.0000,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:30.129969\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.369000\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.363029\n",
      "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1000, 0.0000], device='cuda:0') 0:00:29.930997\n",
      "tensor([0.0000, 0.0000, 0.0100,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:30.093974\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.250029\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.074991\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.240006\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.087994\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.493000\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.321006\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.232000\n",
      "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0100, 0.0000, 0.0000], device='cuda:0') 0:00:30.584994\n",
      "tensor([0.0000, 0.0000, 0.0000,  ..., 0.2700, 0.0000, 0.0100], device='cuda:0') 0:00:29.989005\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.320997\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.241001\n",
      "tensor([0.0000, 0.0000, 0.0300,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:30.450028\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.400003\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.687997\n",
      "tensor([0.0000, 0.0200, 0.0400,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:30.105999\n",
      "tensor([0.0100, 0.0000, 0.0300,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0') 0:00:31.451005\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 0:00:30.529039\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-57dea59f85d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mMO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMainOptuna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SAGE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVERSE_SR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unsupervised'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mMO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-a309ea458c77>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"GCN\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstudy_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" loss, GCN conv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         )\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a309ea458c77>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m#training of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLossSampler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate_catboost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate_catboost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-de1a6f3916b8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model, data, optimizer, Sampler, train_loader, dropout, epoch, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m                         \u001b[0marr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_mask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                         \u001b[0mindices_of_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_of_train_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_of_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MasterDegree\\Code\\modules\\sampling.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, batch, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpos_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0md_pb\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MasterDegree\\Code\\modules\\sampling.py\u001b[0m in \u001b[0;36mpos_sample\u001b[1;34m(self, batch, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mASparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                 \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_sim_rank_for_batch_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mASparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"PPR\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MasterDegree\\Code\\modules\\sampling.py\u001b[0m in \u001b[0;36mfind_sim_rank_for_batch_torch\u001b[1;34m(self, batch, Adj, device)\u001b[0m\n\u001b[0;32m    266\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                             \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                             \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m                                 \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                                 \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "MO = MainOptuna('SAGE', device, VERSE_SR, mode = 'unsupervised')\n",
    "MO.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_sparse import SparseTensor\n",
    "dataset =Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "E = data.num_edges\n",
    "N = data.num_nodes\n",
    "adj = SparseTensor(\n",
    "            row=data.edge_index[0], col=data.edge_index[1],\n",
    "            value=torch.arange(E, device=data.edge_index.device),\n",
    "            sparse_sizes=(N, N))\n",
    "walk_length = 2\n",
    "batch_size=3\n",
    "start = torch.randint(0, N, (batch_size, ), dtype=torch.long).to(device)\n",
    "node_idx = adj.random_walk(start.flatten(), walk_length,p=1,q=0)\n",
    "print(start)\n",
    "print(node_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My__RW_Neighbour.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
