{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-gN3S4NhAjs",
    "outputId": "fef06879-cb42-4f09-db2d-88671e8c4315"
   },
   "outputs": [],
   "source": [
    "#!pip install -q torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 29 17:40:55 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 207... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   42C    P8    30W / 215W |    437MiB /  8192MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       728    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      1264    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      2956    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2996    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      4580    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      8344    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9020    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     10396    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11336    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "|    0   N/A  N/A     12472    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12560    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -q --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install -q --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install -q --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install -q --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install torch-geometric\n",
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "from modules.model import Net\n",
    "from sklearn.metrics import f1_score\n",
    "from modules.sampling import Sampler, SamplerContextMatrix, SamplerRandomWalk,SamplerFactorization,SamplerAPP\n",
    "from datetime import datetime\n",
    "import random\n",
    "from torch_geometric.data import GraphSAINTNodeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "class Main():\n",
    "    def __init__(self,conv, device, loss_function, mode = 'unsupervised',**kwargs):\n",
    "        self.dataset =Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())\n",
    "        data = self.dataset[0]\n",
    "        self.Conv = conv\n",
    "        self.device = device\n",
    "        self.x = data.x\n",
    "        self.y = data.y.squeeze()\n",
    "        self.data=data.to(device)\n",
    "        self.loss = loss_function\n",
    "        self.mode = mode\n",
    "        indices=list(range(len(data.x)))\n",
    "        self.train_indices = torch.tensor(indices[:int(0.6*len(indices)+1)])\n",
    "        self.val_indices = torch.tensor(indices[int(0.6*len(indices)+1):int(0.8*len(indices)+1)])\n",
    "        self.test_indices = torch.tensor(indices[int(0.8*len(indices)+1):])\n",
    "        self.train_mask = torch.tensor([False]*len(indices))\n",
    "        self.test_mask = torch.tensor([False]*len(indices))\n",
    "        self.val_mask = torch.tensor([False]*len(indices))\n",
    "        self.train_mask[self.train_indices] =True\n",
    "        self.test_mask[self.test_indices]=True\n",
    "        self.val_mask[self.val_indices]=True\n",
    "        self.flag = self.loss[\"flag_tosave\"]\n",
    "        \n",
    "        super(Main, self).__init__()\n",
    "    def sampling(self,Sampler,epoch,nodes):\n",
    "        if (epoch == 0): \n",
    "            if self.flag:  \n",
    "                if \"alpha\" in self.loss: \n",
    "                    name_of_file = \"samples_\"+self.loss[\"Name\"]+\"_alpha_\"+str(self.loss[\"alpha\"])+\".pickle\"\n",
    "                else:\n",
    "                    name_of_file = \"samples_\"+self.loss[\"Name\"]+\".pickle\"\n",
    "                \n",
    "                if os.path.exists(name_of_file):\n",
    "                    with open(name_of_file,'rb') as f:\n",
    "                        self.samples = pickle.load(f)\n",
    "                else:\n",
    "                    self.samples = Sampler.sample(nodes) \n",
    "                    with open(name_of_file,'wb') as f:\n",
    "                        pickle.dump(self.samples,f)\n",
    "            else:\n",
    "                \n",
    "                self.samples = Sampler.sample(nodes)\n",
    "        return self.samples\n",
    "    def train(self, model,data,optimizer,Sampler,train_loader,dropout,epoch):\n",
    "        model.train()   \n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        if model.mode == 'unsupervised':\n",
    "            if model.conv=='GCN':\n",
    "                arr=torch.nonzero(self.train_mask == True)\n",
    "                indices_of_train_data = ([item for sublist in arr for item in sublist])\n",
    "                out = model.inference(data.to(device),dp=dropout)\n",
    "                samples = self.sampling(Sampler,epoch, indices_of_train_data)\n",
    "                loss = model.loss(out[self.train_mask], self.samples)\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    if len(train_loader.sizes) == 1:\n",
    "                        adjs = [adjs]\n",
    "                    adjs = [adj.to(device) for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id.to(device)].to(device), adjs)\n",
    "                    samples = self.sampling(Sampler,epoch,n_id[:batch_size])                 \n",
    "                    loss = model.loss(out, self.samples)#pos_batch.to(device), neg_batch.to(device))\n",
    "                    total_loss+=loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()      \n",
    "            return total_loss /len(train_loader)\n",
    "        elif model.mode== 'supervised':\n",
    "            if model.conv=='GCN':\n",
    "                out = model.inference(data.to(device),dp=dropout)\n",
    "                loss = model.loss_sup(out[self.train_mask],y[self.train_mask])\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    adjs = [adj for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id].to(device), adjs)\n",
    "                    loss = model.loss_sup(out,y[n_id[:batch_size]])\n",
    "                    total_loss+=loss\n",
    "            total_loss.backward(retain_graph=True)\n",
    "            optimizer.step()      \n",
    "            return total_loss /len(train_loader)       \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, model,data,classifier,**kwargs):#,n_estimators,learning_rate_carboost, max_depth): \n",
    "        model.eval()\n",
    "        out = model.inference(data.to(device))\n",
    "        y_true = self.y.detach().numpy()\n",
    "        if model.mode == 'supervised':\n",
    "            y_true = self.y.unsqueeze(-1)\n",
    "            y_pred = out.cpu().argmax(dim=-1, keepdim=True)\n",
    "            accs = []\n",
    "            for mask in [self.train_mask, self.val_mask, self.test_mask]:    \n",
    "                accs+=[int(y_pred[mask].eq(y_true[mask]).sum()) / int(mask.sum())]\n",
    "            return accs\n",
    "        elif model.mode == 'unsupervised': \n",
    "            if classifier == 'logistic regression':\n",
    "                clf = LogisticRegression(max_iter = 3000,warm_start=True).fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\n",
    "            else:\n",
    "                n_estimators= kwargs[\"n_estimators\"]\n",
    "                learning_rate_catboost = kwargs[\"learning_rate_catboost\"]\n",
    "                max_depth = kwargs[\"max_depth\"]\n",
    "                clf = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate = learning_rate_catboost, max_depth=max_depth, random_state=0)\n",
    "                clf.fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\n",
    "            accs = []\n",
    "            for mask in [self.train_mask,self.test_mask,self.val_mask]:\n",
    "                accs += [f1_score(self.y.detach()[mask].cpu().numpy(),clf.predict(out.cpu().detach()[mask].numpy()), average='macro')]\n",
    "                \n",
    "            return accs\n",
    "\n",
    "    def run(self,**kwargs):\n",
    "        \n",
    "        hidden_layer = 64\n",
    "        out_layer = 128\n",
    "        dropout = 0.4\n",
    "        size = 2\n",
    "        learning_rate = 0.001\n",
    "\n",
    "        classifier = \"logistic regression\"\n",
    "        train_loader = NeighborSampler(self.data.edge_index, node_idx=self.train_mask, batch_size = int(sum(self.train_mask)), sizes=[-1]*size)\n",
    "        Sampler = self.loss[\"Sampler\"]\n",
    "        LossSampler = Sampler(self.data,device=device,mask=self.train_mask,loss_info=self.loss)\n",
    "        model = Net(dataset = self.dataset,mode=self.mode,conv=self.Conv,loss_function=self.loss,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = (size),dropout = dropout)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)\n",
    "                #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
    "        scheduler=lr_scheduler.StepLR(optimizer, step_size=25,gamma=0.1)\n",
    "        losses=[]\n",
    "        train_accs=[]\n",
    "        test_accs=[]\n",
    "        val_accs=[]\n",
    "        name_of_plot='conv: '+model.conv+', mode: '+model.mode+', loss from '+self.loss[\"Name\"]\n",
    "\n",
    "        print(name_of_plot)\n",
    "\n",
    "        for epoch in range(50):\n",
    "                    print('epoch',epoch)\n",
    "                    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch)\n",
    "                    losses.append(loss)\n",
    "                    train_acc, test_acc,val_acc = self.test(model,self.data,'logistic regression')\n",
    "                    train_accs.append(train_acc)\n",
    "                    test_accs.append(test_acc)\n",
    "                    log = 'Loss: {:.4f}, Epoch: {:03d}, Train: {:.4f}, Test: {:.4f}'\n",
    "                    #scheduler.step()\n",
    "                    print(log.format(loss, epoch, train_acc, test_acc))\n",
    "        print('Test acc on the last epoch ', test_acc)\n",
    "        plt.plot(losses)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "        plt.plot(test_accs)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainOptuna(Main):\n",
    "    def objective(self,trial):\n",
    "        # Integer parameter\n",
    "        hidden_layer = trial.suggest_categorical(\"hidden_layer\", [32,64,128,256])\n",
    "        out_layer = trial.suggest_categorical(\"out_layer\", [32,64,128])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0,0.5,step = 0.1)\n",
    "        size = trial.suggest_categorical(\"size of network, number of convs\", [1,2,3])\n",
    "        Conv = self.Conv\n",
    "        learning_rate= trial.suggest_float(\"lr\",5e-4,1e-2)\n",
    "\n",
    "        # варьируем параметры\n",
    "        loss_to_train={}\n",
    "        for name in self.loss:\n",
    "            \n",
    "            if type(self.loss[name]) == list :\n",
    "                if len(self.loss[name]) == 3:\n",
    "                    var = trial.suggest_int(name,self.loss[name][0],self.loss[name][1],step=self.loss[name][2])\n",
    "                    loss_to_train[name] = var\n",
    "                elif len(self.loss[name]) == 2:\n",
    "                    var_2 = trial.suggest_float(name,self.loss[name][0],self.loss[name][1])\n",
    "                    loss_to_train[name] = var_2\n",
    "                else:\n",
    "                    var_3 = trial.suggest_categorical(name, self.loss[name])\n",
    "                    loss_to_train[name] = var_3\n",
    "            else:\n",
    "                loss_to_train[name] = self.loss[name]\n",
    "        Sampler =loss_to_train[\"Sampler\"]\n",
    "        model = Net(dataset = self.dataset,mode='unsupervised',conv=Conv,loss_function=loss_to_train,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = size,dropout = dropout)\n",
    "        train_loader = NeighborSampler(self.data.edge_index, batch_size = int(sum(self.train_mask)),node_idx=self.train_mask, sizes=[-1]*size)\n",
    "       # train_loader = NeighborSampler(self.data.edge_index, batch_size = int(sum(self.train_mask)), sizes=[-1]*size)\n",
    "        LossSampler = Sampler(self.data,device=self.device,mask=self.train_mask,loss_info=loss_to_train)\n",
    "        model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)  \n",
    "\n",
    "        classifier = \"logistic regression\" #trial.suggest_categorical(\"classifier\", [\"logistic regression\", \"catboost\"])\n",
    "\n",
    "        if classifier == \"catboost\":\n",
    "            n_estimators = trial.suggest_int(\"n of estimators\", 10,40,5)\n",
    "            learning_rate_catboost = trial.suggest_float(\"lr_catboost\",5e-4,1e-2)\n",
    "            max_depth = trial.suggest_int(\"max_depth\",1,10,2)\n",
    "        else:\n",
    "            n_estimators = -1\n",
    "            learning_rate_catboost =-1\n",
    "            max_depth = -1\n",
    "        #training of the model\n",
    "        for epoch in range(50):\n",
    "            loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch)\n",
    "            self.test(model,self.data,classifier,n_estimators=n_estimators,learning_rate_catboost=learning_rate_catboost,max_depth=max_depth)\n",
    "        train_acc, test_acc,val_acc = self.test(model,self.data,classifier,n_estimators=n_estimators,learning_rate_catboost=learning_rate_catboost,max_depth=max_depth)\n",
    "        trial.report(val_acc,epoch)\n",
    "        return val_acc\n",
    "\n",
    "    \n",
    "    def run(self,number_of_trials):\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\",study_name=self.loss[\"Name\"]+\" loss,\"+str(self.Conv)+\" conv\")\n",
    "        study.optimize(self.objective,n_trials = number_of_trials)\n",
    "\n",
    "        print('Best trial:')\n",
    "        trial = study.best_trial\n",
    "        print(\" Value: \", trial.value)\n",
    "        print(\" Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\" {}: {}\".format(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAGE = {\"Name\":\"SAGE\" , \"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":20,\"context size\" : [5,20,5],\"p\":1,\"q\":1, \"loss var\": \"Random Walks\",\"flag\":False,\"Sampler\" =SamplerRandomWalk }\n",
    "from modules.sampling import Sampler, SamplerContextMatrix, SamplerRandomWalk,SamplerFactorization,SamplerAPP\n",
    "DeepWalk = {\"Name\": \"DeepWalk\",\"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":[1,21,5],\"context_size\" : [5,20,5],\"p\":1,\"q\":1,\"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\" : SamplerRandomWalk } #Проблемы с памятью после того, как увеличила количество тренировочных данных\n",
    "Node2Vec = {\"Name\": \"Node2Vec\",\"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":[1,21,5],\"context_size\" : [5,20,5],\"p\": [0.0,0.9] ,\"q\":[0.0,0.9], \"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\": SamplerRandomWalk}#то же самое \n",
    "\n",
    "LINE = {\"Name\": \"LINE\",\"C\": \"Adj\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"Sampler\" :SamplerContextMatrix} \n",
    "\n",
    "HOPE_RPR = {\"Name\": \"HOPE_RPR\",\"C\":\"RPR\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"alpha\": [0,1],\"Sampler\" :SamplerFactorization} #проверить\n",
    "HOPE_Katz = {\"Name\": \"HOPE_Katz\",\"C\":\"Katz\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"betta\": [0,1],\"Sampler\" :SamplerFactorization,} #проверить\n",
    "HOPE_CN = {\"Name\": \"HOPE_CommonNeighbors\",\"C\":\"CN\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization} \n",
    "HOPE_AA = {\"Name\": \"HOPE_AdamicAdar\",\"C\":\"AA\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization} \n",
    "\n",
    "LapEigen = {\"Name\": \"LaplacianEigenMaps\", \"C\":\"Adj\",\"loss var\": \"Laplacian EigenMaps\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization}\n",
    "GraphFactorization = {\"Name\": \"Graph Factorization\",\"C\":\"Adj\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization} \n",
    "\n",
    "VERSE_PPR =  {\"Name\": \"VERSE_PPR\",\"C\": \"PPR\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerContextMatrix}\n",
    "VERSE_SR =  {\"Name\": \"VERSE_SimRank\",\"C\": \"SR\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"Sampler\":SamplerContextMatrix} \n",
    "VERSE_Adj =  {\"Name\": \"VERSE_Adj\",\"C\": \"Adj\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"Sampler\" :SamplerContextMatrix} \n",
    "\n",
    "APP ={\"Name\": \"APP\",\"C\": \"PPR\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerAPP}\n",
    "\n",
    "Struc2Vec ={} #Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-29 17:40:59,606]\u001b[0m A new study created in memory with name: HOPE_Katz loss,SAGE conv\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:05,342]\u001b[0m Trial 0 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0026761140454001297, 'betta': 0.4293457138451553}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:10,324]\u001b[0m Trial 1 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.003369628628194932, 'betta': 0.06864739281873389}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:15,016]\u001b[0m Trial 2 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00972920451053798, 'betta': 0.5787427799159128}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:20,281]\u001b[0m Trial 3 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0007768017348466259, 'betta': 0.9812405159372746}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:25,859]\u001b[0m Trial 4 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0018174827548679347, 'betta': 0.3092210741992302}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:31,104]\u001b[0m Trial 5 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0067337898175483316, 'betta': 0.039089762303872955}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:37,052]\u001b[0m Trial 6 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0030081199015921244, 'betta': 0.5933635058425485}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:42,552]\u001b[0m Trial 7 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00957729456622898, 'betta': 0.5063461093730793}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:47,706]\u001b[0m Trial 8 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.0015791664914576336, 'betta': 0.4808052218197172}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:52,986]\u001b[0m Trial 9 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.004437406302557645, 'betta': 0.28122131600104616}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:41:58,805]\u001b[0m Trial 10 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006651392743907377, 'betta': 0.8702128795157029}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:42:03,977]\u001b[0m Trial 11 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.003816795558538229, 'betta': 0.04970576634843748}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:42:08,957]\u001b[0m Trial 12 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005763517483919905, 'betta': 0.29959018712233443}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:42:14,425]\u001b[0m Trial 13 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0030884097603191734, 'betta': 0.1468725453324664}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:42:19,639]\u001b[0m Trial 14 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.002156673925752802, 'betta': 0.7759809299478911}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:42:24,417]\u001b[0m Trial 15 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.004721536725937883, 'betta': 0.19903924567197245}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:42:29,997]\u001b[0m Trial 16 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0008367193615034995, 'betta': 0.4052873304665618}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n",
      "\u001b[32m[I 2021-04-29 17:42:35,209]\u001b[0m Trial 17 finished with value: 0.06760563380281691 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0021485311437327006, 'betta': 0.7501172773236557}. Best is trial 0 with value: 0.06760563380281691.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6d49ab6870dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHOPE_Katz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mMO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMainOptuna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SAGE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unsupervised'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mMO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-989948d806c3>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, number_of_trials)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstudy_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" loss,\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" conv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumber_of_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         )\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-989948d806c3>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m#training of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLossSampler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate_catboost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate_catboost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate_catboost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate_catboost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-2c48e9732a62>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model, data, optimizer, Sampler, train_loader, dropout, epoch)\u001b[0m\n\u001b[0;32m     64\u001b[0m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSampler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#pos_batch.to(device), neg_batch.to(device))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m                     \u001b[0mtotal_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MasterDegree\\Code\\modules\\model.py\u001b[0m in \u001b[0;36mlossFactorization\u001b[1;34m(self, out, S)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlossLaplacianEigenMaps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss = HOPE_Katz\n",
    "MO = MainOptuna('SAGE', device, loss , mode = 'unsupervised')\n",
    "MO.run(number_of_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: SAGE, mode: unsupervised, loss from HOPE_Katz\n",
      "epoch 0\n",
      "Loss: 569085.2500, Epoch: 000, Train: 0.0649, Test: 0.0689\n",
      "epoch 1\n",
      "Loss: 484617.9375, Epoch: 001, Train: 0.0649, Test: 0.0689\n",
      "epoch 2\n",
      "Loss: 412976.4375, Epoch: 002, Train: 0.0649, Test: 0.0689\n",
      "epoch 3\n",
      "Loss: 348628.0000, Epoch: 003, Train: 0.0649, Test: 0.0689\n",
      "epoch 4\n",
      "Loss: 293215.9688, Epoch: 004, Train: 0.0649, Test: 0.0689\n",
      "epoch 5\n",
      "Loss: 243711.3125, Epoch: 005, Train: 0.0649, Test: 0.0689\n",
      "epoch 6\n",
      "Loss: 198602.1875, Epoch: 006, Train: 0.0649, Test: 0.0689\n",
      "epoch 7\n",
      "Loss: 159025.2969, Epoch: 007, Train: 0.0649, Test: 0.0689\n",
      "epoch 8\n",
      "Loss: 124102.0547, Epoch: 008, Train: 0.0649, Test: 0.0689\n",
      "epoch 9\n",
      "Loss: 95926.3750, Epoch: 009, Train: 0.0649, Test: 0.0689\n",
      "epoch 10\n",
      "Loss: 71828.2812, Epoch: 010, Train: 0.0649, Test: 0.0689\n",
      "epoch 11\n",
      "Loss: 54219.6484, Epoch: 011, Train: 0.0649, Test: 0.0689\n",
      "epoch 12\n",
      "Loss: 40062.1992, Epoch: 012, Train: 0.0649, Test: 0.0689\n",
      "epoch 13\n",
      "Loss: 29999.8691, Epoch: 013, Train: 0.0649, Test: 0.0689\n",
      "epoch 14\n",
      "Loss: 23508.2246, Epoch: 014, Train: 0.0649, Test: 0.0689\n",
      "epoch 15\n",
      "Loss: 18310.0762, Epoch: 015, Train: 0.0649, Test: 0.0689\n",
      "epoch 16\n",
      "Loss: 14815.9854, Epoch: 016, Train: 0.0649, Test: 0.0689\n",
      "epoch 17\n",
      "Loss: 12872.9492, Epoch: 017, Train: 0.0649, Test: 0.0689\n",
      "epoch 18\n",
      "Loss: 10921.8926, Epoch: 018, Train: 0.0649, Test: 0.0689\n",
      "epoch 19\n",
      "Loss: 9821.6602, Epoch: 019, Train: 0.0649, Test: 0.0689\n",
      "epoch 20\n",
      "Loss: 8442.4697, Epoch: 020, Train: 0.0649, Test: 0.0689\n",
      "epoch 21\n",
      "Loss: 8214.7334, Epoch: 021, Train: 0.0649, Test: 0.0689\n",
      "epoch 22\n",
      "Loss: 7016.7515, Epoch: 022, Train: 0.0649, Test: 0.0689\n",
      "epoch 23\n",
      "Loss: 6578.4805, Epoch: 023, Train: 0.0649, Test: 0.0689\n",
      "epoch 24\n",
      "Loss: 5581.8760, Epoch: 024, Train: 0.0649, Test: 0.0689\n",
      "epoch 25\n",
      "Loss: 4812.8906, Epoch: 025, Train: 0.0649, Test: 0.0689\n",
      "epoch 26\n",
      "Loss: 4411.4541, Epoch: 026, Train: 0.0649, Test: 0.0689\n",
      "epoch 27\n",
      "Loss: 3821.4524, Epoch: 027, Train: 0.0649, Test: 0.0689\n",
      "epoch 28\n",
      "Loss: 3219.6296, Epoch: 028, Train: 0.0649, Test: 0.0689\n",
      "epoch 29\n",
      "Loss: 2816.7539, Epoch: 029, Train: 0.0649, Test: 0.0689\n",
      "epoch 30\n",
      "Loss: 2346.9753, Epoch: 030, Train: 0.0649, Test: 0.0689\n",
      "epoch 31\n",
      "Loss: 1985.4211, Epoch: 031, Train: 0.0649, Test: 0.0689\n",
      "epoch 32\n",
      "Loss: 1542.9558, Epoch: 032, Train: 0.0649, Test: 0.0689\n",
      "epoch 33\n",
      "Loss: 1340.5404, Epoch: 033, Train: 0.0649, Test: 0.0689\n",
      "epoch 34\n",
      "Loss: 1085.1149, Epoch: 034, Train: 0.0649, Test: 0.0689\n",
      "epoch 35\n",
      "Loss: 984.6080, Epoch: 035, Train: 0.0649, Test: 0.0689\n",
      "epoch 36\n",
      "Loss: 867.7906, Epoch: 036, Train: 0.0649, Test: 0.0689\n",
      "epoch 37\n",
      "Loss: 784.0093, Epoch: 037, Train: 0.0649, Test: 0.0689\n",
      "epoch 38\n",
      "Loss: 647.3376, Epoch: 038, Train: 0.0649, Test: 0.0689\n",
      "epoch 39\n",
      "Loss: 609.7977, Epoch: 039, Train: 0.0649, Test: 0.0689\n",
      "epoch 40\n",
      "Loss: 544.7310, Epoch: 040, Train: 0.0649, Test: 0.0689\n",
      "epoch 41\n",
      "Loss: 477.5144, Epoch: 041, Train: 0.0649, Test: 0.0689\n",
      "epoch 42\n",
      "Loss: 452.0889, Epoch: 042, Train: 0.0649, Test: 0.0689\n",
      "epoch 43\n",
      "Loss: 421.1328, Epoch: 043, Train: 0.0649, Test: 0.0689\n",
      "epoch 44\n",
      "Loss: 408.1692, Epoch: 044, Train: 0.0649, Test: 0.0689\n",
      "epoch 45\n",
      "Loss: 396.3791, Epoch: 045, Train: 0.0649, Test: 0.0689\n",
      "epoch 46\n",
      "Loss: 362.6109, Epoch: 046, Train: 0.0649, Test: 0.0689\n",
      "epoch 47\n",
      "Loss: 363.3992, Epoch: 047, Train: 0.0649, Test: 0.0689\n",
      "epoch 48\n",
      "Loss: 325.5373, Epoch: 048, Train: 0.0649, Test: 0.0689\n",
      "epoch 49\n",
      "Loss: 332.6273, Epoch: 049, Train: 0.0649, Test: 0.0689\n",
      "Test acc on the last epoch  0.06892406331396514\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "APP ={\"Name\": \"APP\",\"C\": \"PPR\",\"num_negative_samples\":1,\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"alpha\": 0.9,\"Sampler\" :SamplerAPP}\n",
    "\n",
    "loss = HOPE_Katz \n",
    "MO = Main('SAGE', device, loss , mode = 'unsupervised')\n",
    "MO.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "MO = MainOptuna('SAGE', device, loss, mode = 'unsupervised',number_of_trials=20)\n",
    "MO.run(number_of_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "MO = MainOptuna('GAT', device, loss, mode = 'unsupervised')\n",
    "MO.run(number_of_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My__RW_Neighbour.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
