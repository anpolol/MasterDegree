{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-gN3S4NhAjs",
    "outputId": "fef06879-cb42-4f09-db2d-88671e8c4315"
   },
   "outputs": [],
   "source": [
    "#!pip install -q torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -q --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n",
    "#!pip install -q --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n",
    "#!pip install -q --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n",
    "#!pip install -q --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n",
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# link prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "from modules.model import Net\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import optuna\n",
    "from modules.negativeSampling import NegativeSampler\n",
    "from modules.sampling import Sampler, SamplerContextMatrix, SamplerRandomWalk,SamplerFactorization,SamplerAPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from torch_geometric.datasets import Flickr\n",
    "class Main():\n",
    "    def __init__(self,conv, device, loss_function, mode = 'unsupervised',**kwargs):\n",
    "        #self.dataset =Flickr(root='/tmp/Flickr',transform=T.NormalizeFeatures())\n",
    "        self.dataset =Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())\n",
    "        \n",
    "        data = self.dataset[0]\n",
    "        self.Conv = conv\n",
    "        self.device = device\n",
    "        self.x = data.x\n",
    "        self.y = data.y.squeeze()\n",
    "        self.data=data.to(device)\n",
    "        self.dataprocess(data)\n",
    "        self.loss = loss_function\n",
    "        self.mode = mode\n",
    "        self.train_mask = torch.tensor([True]*int(0.8*len(data.x)+1) + [False]*int(0.2*len(data.x)))\n",
    "        #val_mask = torch.tensor([False]*int(0.6*len(data.x)+1) + [True]*int(0.2*len(data.x)+1)+[False]*int(0.2*len(data.x)))\n",
    "        self.test_mask = torch.tensor([False]*int(0.8*len(data.x)+1) + [True]*int(0.2*len(data.x)))\n",
    "        self.flag = self.loss[\"flag_tosave\"]\n",
    "        \n",
    "        super(Main, self).__init__()\n",
    "    def dataprocess(self,data):\n",
    "        #splitting data to train and test\n",
    "        train_edge_index = []\n",
    "        test_edge_index = []\n",
    "        val_edge_index = []\n",
    "        d = datetime.now()\n",
    "        indices_to_delete_for_val  = random.choices(list(range(len(data.edge_index[0]))), k = int(len(data.edge_index[0])*0.2))\n",
    "        indices_to_delete_for_test  = random.choices( list(set(range(len(data.edge_index[0]))) - set(indices_to_delete_for_val)) , k = int(len(list(set(range(len(data.edge_index[0]))) - set(indices_to_delete_for_val))) *0.625))\n",
    "      #  print(datetime.now()-d)\n",
    "        d = datetime.now()\n",
    "        for i,x in enumerate(list(zip(*data.edge_index.tolist()))):\n",
    "            if i in indices_to_delete_for_test:\n",
    "                test_edge_index.append(x)\n",
    "            elif i in indices_to_delete_for_val: \n",
    "                val_edge_index.append(x)\n",
    "            else: \n",
    "                train_edge_index.append(x)\n",
    "        val_edge_index = torch.tensor(np.array(list(zip(*val_edge_index))))\n",
    "        test_edge_index = torch.tensor(np.array(list(zip(*test_edge_index))))\n",
    "        train_edge_index = torch.tensor(np.array(list(zip(*train_edge_index))), dtype = torch.long)\n",
    "       # print(datetime.now()-d)\n",
    "        d = datetime.now()\n",
    "        s = set(itertools.combinations(range(len(data.x)), 2))\n",
    "       # print(datetime.now()-d)\n",
    "        d = datetime.now()\n",
    "        s_of_edges = set()\n",
    "        for pair in (data.edge_index.t().tolist()):\n",
    "            s_of_edges.add(tuple(pair))\n",
    "        s_of_non_edges = s - s_of_edges\n",
    "        #append negative samples to test set\n",
    "        non_edges=[]\n",
    "      #  print(datetime.now()-d)\n",
    "        d = datetime.now()\n",
    "        for pair in list(s_of_non_edges):\n",
    "            non_edges.append(list(pair))\n",
    "      #  print(datetime.now()-d)\n",
    "        d = datetime.now()   \n",
    "        self.non_edges_test=torch.tensor(random.choices(non_edges, k = len(test_edge_index[0]))).t()\n",
    "        self.non_edges_val=torch.tensor(random.choices(non_edges, k = len(val_edge_index[0]))).t()\n",
    "        self.y_true_val = [1]*len(val_edge_index[0])\n",
    "        self.y_true_test = [1]*len(test_edge_index[0])\n",
    "        self.test_edge_index=torch.cat((test_edge_index,self.non_edges_test),1)\n",
    "        self.val_edge_index=torch.cat((val_edge_index,self.non_edges_val),1)\n",
    "        self.y_true_test += [0]*len(self.non_edges_test[0])\n",
    "        self.y_true_val += [0]*len(self.non_edges_val[0])\n",
    "        self.data.edge_index = train_edge_index\n",
    "    \n",
    "    def sampling(self,Sampler,epoch,nodes):\n",
    "        if (epoch == 0): \n",
    "            if self.flag:  \n",
    "                if \"alpha\" in self.loss: \n",
    "                    name_of_file = \"LP_samples_\"+self.loss[\"Name\"]+\"_alpha_\"+str(self.loss[\"alpha\"])+\".pickle\"\n",
    "                else:\n",
    "                    name_of_file = \"LP_samples_\"+self.loss[\"Name\"]+\".pickle\"\n",
    "                \n",
    "                if os.path.exists(name_of_file):\n",
    "                    with open(name_of_file,'rb') as f:\n",
    "                        self.samples = pickle.load(f)\n",
    "                else:\n",
    "                    self.samples = Sampler.sample(nodes) \n",
    "                    with open(name_of_file,'wb') as f:\n",
    "                        self.samples = pickle.dump(self.samples,f)\n",
    "            else:\n",
    "                \n",
    "                self.samples = Sampler.sample(nodes)\n",
    "        return self.samples\n",
    "    def train(self, model,data,optimizer,Sampler,train_loader,dropout,epoch):\n",
    "        model.train()   \n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        if model.mode == 'unsupervised':\n",
    "            if model.conv=='GCN':\n",
    "                arr=torch.nonzero(self.train_mask == True)\n",
    "                indices_of_train_data = ([item for sublist in arr for item in sublist])\n",
    "                out = model.inference(data.to(device),dp=dropout)\n",
    "                samples = self.sampling(Sampler,epoch, indices_of_train_data)\n",
    "                loss = model.loss(out[self.train_mask], self.samples)\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    if len(train_loader.sizes) == 1:\n",
    "                        adjs = [adjs]\n",
    "                    adjs = [adj.to(device) for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id.to(device)].to(device), adjs)\n",
    "                    samples = self.sampling(Sampler,epoch,n_id[:batch_size])   \n",
    "                   \n",
    "                #print(out.shape, self.samples.shape)\n",
    "                    loss = model.loss(out, self.samples)#pos_batch.to(device), neg_batch.to(device))\n",
    "                    total_loss+=loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()      \n",
    "            return total_loss# /len(train_loader)\n",
    "        elif model.mode== 'supervised':\n",
    "            if model.conv=='GCN':\n",
    "                out = model.inference(data.to(device),dp=dropout)\n",
    "                loss = model.loss_sup(out[self.train_mask],y[self.train_mask])\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    adjs = [adj for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id].to(device), adjs)\n",
    "                    loss = model.loss_sup(out,y[n_id[:batch_size]])\n",
    "                    total_loss+=loss\n",
    "            total_loss.backward(retain_graph=True)\n",
    "            optimizer.step()      \n",
    "            return total_loss #/len(train_loader)  \n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def val_lp(self,model,data,classifier): \n",
    "        model.eval()\n",
    "        out = model.inference(data.to(device))\n",
    "        y_true = np.array(self.y_true_val)\n",
    "        if model.mode == 'unsupervised':\n",
    "            y_pred = []\n",
    "            for x in list(zip(*self.val_edge_index)):\n",
    "                y_pred.append(torch.sigmoid(torch.dot(out[x[0]],out[x[1]])))#print(torch.sigmoid(torch.dot(out[x[0]],out[x[1]])))\n",
    "            return roc_auc_score(y_true,np.array(y_pred)) \n",
    "            #return [precision_score(y_true[train_mask.cpu()], best_preds_train, average='macro'), precision_score(y_true[val_mask.cpu()], best_preds_val, average='macro'),precision_score(y_true[test_mask.cpu()], best_preds, average='macro')]\n",
    "    def test_lp(self,model,data,classifier): \n",
    "        model.eval()\n",
    "        out = model.inference(data.to(device))\n",
    "        y_true = np.array(self.y_true_test)\n",
    "        if model.mode == 'unsupervised':\n",
    "            y_pred = []\n",
    "            for x in list(zip(*self.test_edge_index)):\n",
    "                y_pred.append(torch.sigmoid(torch.dot(out[x[0]],out[x[1]])))#print(torch.sigmoid(torch.dot(out[x[0]],out[x[1]])))\n",
    "            return roc_auc_score(y_true,np.array(y_pred)) \n",
    "      \n",
    "    def run(self,**kwargs):\n",
    "        hidden_layer = 32\n",
    "        out_layer = 64\n",
    "        dropout =  0.4\n",
    "        size = 1\n",
    "\n",
    "        learning_rate = 0.007\n",
    "    \n",
    "        classifier = \"logistic regression\"\n",
    "        train_loader = NeighborSampler(self.data.edge_index, batch_size = int(len(self.data.x)), sizes=[-1]*size)\n",
    "        Sampler=self.loss[\"Sampler\"]\n",
    "        LossSampler = Sampler(self.data,device=device,mask=self.train_mask,loss_info=self.loss)\n",
    "        model = Net(dataset = self.dataset,mode=self.mode,conv=self.Conv,loss_function=self.loss,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = (size),dropout = dropout)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)\n",
    "                #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
    "        scheduler=lr_scheduler.StepLR(optimizer, step_size=25,gamma=0.1)\n",
    "        losses=[]\n",
    "        train_accs=[]\n",
    "        test_accs=[]\n",
    "        val_accs=[]\n",
    "        name_of_plot='conv: '+model.conv+', mode: '+model.mode+', loss from '+self.loss[\"Name\"]\n",
    "\n",
    "        print(name_of_plot)\n",
    "\n",
    "        for epoch in range(100):\n",
    "                    print('epoch',epoch)\n",
    "                    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch)\n",
    "                    losses.append(loss)\n",
    "                    d_test = datetime.now()\n",
    "                    test_acc = self.test_lp(model,self.data,'logistic regression')\n",
    "                    test_accs.append(test_acc)\n",
    "                    log = 'Loss: {:.4f}, Epoch: {:03d}, Test: {:.4f}'\n",
    "                    #scheduler.step()\n",
    "                    print(log.format(loss, epoch, test_acc))\n",
    "        print('Test acc on the last epoch ', test_acc)\n",
    "        plt.plot(losses)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "        plt.plot(test_accs)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "                    #return [precision_score(y_true[train_mask.cpu()], best_preds_train, average='macro'), precision_score(y_true[val_mask.cpu()], best_preds_val, average='macro'),precision_score(y_true[test_mask.cpu()], best_preds, average='macro')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainOptuna(Main):\n",
    "    def objective(self,trial):\n",
    "        # Integer parameter\n",
    "        hidden_layer = trial.suggest_categorical(\"hidden_layer\", [32,64,128,256])\n",
    "        out_layer = trial.suggest_categorical(\"out_layer\", [32,64,128])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0,0.5,step = 0.1)\n",
    "        size = trial.suggest_categorical(\"size of network, number of convs\", [1,2,3])\n",
    "        Conv = self.Conv# trial.suggest_categorical(\"conv\", [\"SAGE\",\"GCN\",\"GAT\"])\n",
    "\n",
    "        # варьируем параметры\n",
    "        loss_to_train={}\n",
    "        for name in self.loss:\n",
    "            \n",
    "            if type(self.loss[name]) == list :\n",
    "                if len(self.loss[name]) == 3:\n",
    "                    var = trial.suggest_int(name,self.loss[name][0],self.loss[name][1],step=self.loss[name][2])\n",
    "                    loss_to_train[name] = var\n",
    "                elif len(self.loss[name]) == 2:\n",
    "                    var_2 = trial.suggest_float(name,self.loss[name][0],self.loss[name][1])\n",
    "                    loss_to_train[name] = var_2\n",
    "                else:\n",
    "                    var_3 = trial.suggest_categorical(name, self.loss[name])\n",
    "                    loss_to_train[name] = var_3\n",
    "            else:\n",
    "                loss_to_train[name] = self.loss[name]\n",
    "        Sampler =loss_to_train[\"Sampler\"]\n",
    "        model = Net(dataset = self.dataset,mode='unsupervised',conv=Conv,loss_function=loss_to_train,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = size,dropout = dropout)\n",
    "\n",
    "        train_loader = NeighborSampler(self.data.edge_index, batch_size =int(len(self.data.x)), sizes=[-1]*size)\n",
    "        \n",
    "        #train_loader = GraphSAINTRandomWalkSampler(data, batch_size=2176, walk_length=2,num_steps=5, sample_coverage=100,save_dir=dataset.processed_dir,num_workers=4)\n",
    "\n",
    "        LossSampler = Sampler(self.data,device=self.device,mask=self.train_mask,loss_info=loss_to_train)\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        learning_rate= trial.suggest_float(\"lr\",5e-4,1e-2)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)  \n",
    "\n",
    "        classifier = \"logistic regression\" #trial.suggest_categorical(\"classifier\", [\"logistic regression\", \"catboost\"])\n",
    "\n",
    "        if classifier == \"catboost\":\n",
    "            n_estimators = trial.suggest_int(\"n of estimators\", 10,40,5)\n",
    "            learning_rate_catboost = trial.suggest_float(\"lr_catboost\",5e-4,1e-2)\n",
    "            max_depth = trial.suggest_int(\"max_depth\",1,10,2)\n",
    "        else:\n",
    "            n_estimators = -1\n",
    "            learning_rate_catboost =-1\n",
    "            max_depth = -1\n",
    "        #training of the model\n",
    "        for epoch in range(50):\n",
    "            loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch)\n",
    "            #print(loss)\n",
    "\n",
    "        val_acc = self.val_lp(model,self.data,classifier)\n",
    "\n",
    "\n",
    "        trial.report(val_acc,epoch)\n",
    "\n",
    "        return val_acc\n",
    "\n",
    "    \n",
    "    def run(self,number_of_trials):\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\",study_name=self.loss[\"Name\"]+\" loss,\"+str(self.Conv)+\" conv\")\n",
    "        study.optimize(self.objective,n_trials = number_of_trials)\n",
    "\n",
    "        print('Best trial:')\n",
    "        trial = study.best_trial\n",
    "        print(\" Value: \", trial.value)\n",
    "        print(\" Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\" {}: {}\".format(key,value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " #SAGE = {\"Name\":\"SAGE\" , \"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":20,\"context size\" : [5,20,5],\"p\":1,\"q\":1, \"loss var\": \"Random Walks\",\"flag\":False,\"Sampler\" =SamplerRandomWalk }\n",
    "from modules.sampling import Sampler, SamplerContextMatrix, SamplerRandomWalk,SamplerFactorization,SamplerAPP\n",
    "DeepWalk = {\"Name\": \"DeepWalk\",\"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":[1,21,5],\"context_size\" : [5,20,5],\"p\":1,\"q\":1,\"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\" : SamplerRandomWalk } #Проблемы с памятью после того, как увеличила количество тренировочных данных\n",
    "Node2Vec = {\"Name\": \"Node2Vec\",\"walk_length\":[5,20,5],\"walks_per_node\":[5,20,5],\"num_negative_samples\":[1,21,5],\"context_size\" : [5,20,5],\"p\": [0.0,0.9] ,\"q\":[0.0,0.9], \"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\": SamplerRandomWalk}#то же самое \n",
    "\n",
    "LINE = {\"Name\": \"LINE\",\"C\": \"Adj\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"Sampler\" :SamplerContextMatrix} \n",
    "HOPE_RPR = {\"Name\": \"HOPE_RPR\",\"C\":\"RPR\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"alpha\": [0,1],\"Sampler\" :SamplerFactorization} #проверить\n",
    "HOPE_Katz = {\"Name\": \"HOPE_Katz\",\"C\":\"Katz\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"betta\": [0,1],\"Sampler\" :SamplerFactorization,} #проверить\n",
    "HOPE_CN = {\"Name\": \"HOPE_CommonNeighbors\",\"C\":\"CN\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization} \n",
    "HOPE_AA = {\"Name\": \"HOPE_AdamicAdar\",\"C\":\"AA\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization} \n",
    "\n",
    "LapEigen = {\"Name\": \"LaplacianEigenMaps\", \"C\":\"Adj\",\"loss var\": \"Laplacian EigenMaps\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization}\n",
    "GraphFactorization = {\"Name\": \"Graph Factorization\",\"C\":\"Adj\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization} \n",
    "\n",
    "VERSE_PPR =  {\"Name\": \"VERSE_PPR\",\"C\": \"PPR\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerContextMatrix}\n",
    "VERSE_SR =  {\"Name\": \"VERSE_SimRank\",\"C\": \"SR\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"Sampler\":SamplerContextMatrix} \n",
    "VERSE_Adj =  {\"Name\": \"VERSE_Adj\",\"C\": \"Adj\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"Sampler\" :SamplerContextMatrix} \n",
    "\n",
    "APP ={\"Name\": \"APP\",\"C\": \"PPR\",\"num_negative_samples\":[1,21,5],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerAPP}\n",
    "\n",
    "Struc2Vec ={} #Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-26 19:30:03,485]\u001b[0m A new study created in memory with name: Graph Factorization loss,SAGE conv\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:30:10,772]\u001b[0m Trial 0 finished with value: 0.5840489003129946 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00672213854826853}. Best is trial 0 with value: 0.5840489003129946.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:30:18,063]\u001b[0m Trial 1 finished with value: 0.522892655129599 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006474405474024392}. Best is trial 0 with value: 0.5840489003129946.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:30:25,401]\u001b[0m Trial 2 finished with value: 0.5448886089743181 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.004253665274610616}. Best is trial 0 with value: 0.5840489003129946.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:30:32,752]\u001b[0m Trial 3 finished with value: 0.8803628091308846 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008962481330408119}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:30:40,172]\u001b[0m Trial 4 finished with value: 0.5027657859411738 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.006941757408511136}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:30:47,619]\u001b[0m Trial 5 finished with value: 0.4535859888245092 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.0056909808852696805}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:30:55,067]\u001b[0m Trial 6 finished with value: 0.5667749829058103 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0014100625091488569}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:31:02,417]\u001b[0m Trial 7 finished with value: 0.8256236300781367 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.002054123259622091}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:31:09,796]\u001b[0m Trial 8 finished with value: 0.5343396053075418 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007732750703053334}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:31:17,205]\u001b[0m Trial 9 finished with value: 0.5601604792294872 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007567351155059753}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:31:24,512]\u001b[0m Trial 10 finished with value: 0.8570339097255217 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009935690960990003}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:31:31,813]\u001b[0m Trial 11 finished with value: 0.8342536016786757 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009911515885468727}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:31:39,103]\u001b[0m Trial 12 finished with value: 0.8730569281485063 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00928265975299691}. Best is trial 3 with value: 0.8803628091308846.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:31:46,393]\u001b[0m Trial 13 finished with value: 0.8828691729290019 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008742636227587242}. Best is trial 13 with value: 0.8828691729290019.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:31:53,673]\u001b[0m Trial 14 finished with value: 0.8662400060213609 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00867314832668555}. Best is trial 13 with value: 0.8828691729290019.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:00,949]\u001b[0m Trial 15 finished with value: 0.8180601256128934 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.003915863672267196}. Best is trial 13 with value: 0.8828691729290019.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:08,221]\u001b[0m Trial 16 finished with value: 0.8810165529313874 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008786552304717567}. Best is trial 13 with value: 0.8828691729290019.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:15,484]\u001b[0m Trial 17 finished with value: 0.8742035048415782 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008370890654691612}. Best is trial 13 with value: 0.8828691729290019.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:22,936]\u001b[0m Trial 18 finished with value: 0.5201348939800504 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009997389948970599}. Best is trial 13 with value: 0.8828691729290019.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:30,399]\u001b[0m Trial 19 finished with value: 0.822327101021888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0050571400847922564}. Best is trial 13 with value: 0.8828691729290019.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:37,750]\u001b[0m Trial 20 finished with value: 0.8967595337983468 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007606628391989666}. Best is trial 20 with value: 0.8967595337983468.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:45,073]\u001b[0m Trial 21 finished with value: 0.8907414935133395 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008116064944863872}. Best is trial 20 with value: 0.8967595337983468.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:52,312]\u001b[0m Trial 22 finished with value: 0.8925912079829519 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007947053499760477}. Best is trial 20 with value: 0.8967595337983468.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:32:59,564]\u001b[0m Trial 23 finished with value: 0.8836943428816363 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007588014391975369}. Best is trial 20 with value: 0.8967595337983468.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:33:06,803]\u001b[0m Trial 24 finished with value: 0.8383191271461821 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00607918769080189}. Best is trial 20 with value: 0.8967595337983468.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:33:14,055]\u001b[0m Trial 25 finished with value: 0.9122201250151847 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007717809516861157}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:33:21,243]\u001b[0m Trial 26 finished with value: 0.9021180192268472 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007133983109984896}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:33:28,657]\u001b[0m Trial 27 finished with value: 0.6471930800838231 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005079652819010124}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:33:35,919]\u001b[0m Trial 28 finished with value: 0.9030873587117829 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00708013102565441}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-26 19:33:43,178]\u001b[0m Trial 29 finished with value: 0.8853359662028982 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006919778262092863}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:33:50,434]\u001b[0m Trial 30 finished with value: 0.8660934843949625 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006746842155866559}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:33:57,692]\u001b[0m Trial 31 finished with value: 0.8955031004750952 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007147385296914701}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:34:04,945]\u001b[0m Trial 32 finished with value: 0.8695705712627784 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006128735007966314}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:34:12,194]\u001b[0m Trial 33 finished with value: 0.8906897474432046 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006359307828015223}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:34:19,465]\u001b[0m Trial 34 finished with value: 0.8838921955027407 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009356164474434677}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:34:26,822]\u001b[0m Trial 35 finished with value: 0.642843781381432 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.004292442469579169}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:34:34,088]\u001b[0m Trial 36 finished with value: 0.8840258497908435 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005582067489226366}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:34:41,414]\u001b[0m Trial 37 finished with value: 0.8950930059513514 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007480359474293964}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:34:48,914]\u001b[0m Trial 38 finished with value: 0.5459921561812617 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.00658228362318681}. Best is trial 25 with value: 0.9122201250151847.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:34:56,180]\u001b[0m Trial 39 finished with value: 0.9178121595516742 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007195871717666327}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:35:03,513]\u001b[0m Trial 40 finished with value: 0.5735801445624704 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005699957302078178}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:35:10,774]\u001b[0m Trial 41 finished with value: 0.9065951611613369 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00831155385469885}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:35:18,035]\u001b[0m Trial 42 finished with value: 0.8807150698115365 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007209301103366434}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:35:25,300]\u001b[0m Trial 43 finished with value: 0.8844818793287179 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008322563315108103}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:35:32,572]\u001b[0m Trial 44 finished with value: 0.8901722867418544 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009368485092709808}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:35:39,991]\u001b[0m Trial 45 finished with value: 0.5533378844048136 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007241778390322213}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:35:47,258]\u001b[0m Trial 46 finished with value: 0.893048897822542 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00817327979566802}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:35:54,535]\u001b[0m Trial 47 finished with value: 0.8785598598262605 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0067568556484012745}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:36:01,798]\u001b[0m Trial 48 finished with value: 0.9046292255716349 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009110065827323068}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 19:36:09,068]\u001b[0m Trial 49 finished with value: 0.9033178639332935 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009071230478597911}. Best is trial 39 with value: 0.9178121595516742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " Value:  0.9178121595516742\n",
      " Params: \n",
      " hidden_layer: 256\n",
      " out_layer: 64\n",
      " dropout: 0.4\n",
      " size of network, number of convs: 1\n",
      " lr: 0.007195871717666327\n"
     ]
    }
   ],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "loss = GraphFactorization\n",
    "MO = MainOptuna('SAGE', device, loss , mode = 'unsupervised')\n",
    "MO.run(number_of_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: SAGE, mode: unsupervised, loss from Graph Factorization\n",
      "epoch 0\n",
      "Loss: 3055.4734, Epoch: 000, Test: 0.5995\n",
      "epoch 1\n",
      "Loss: 2417.7485, Epoch: 001, Test: 0.5852\n",
      "epoch 2\n",
      "Loss: 2859.0552, Epoch: 002, Test: 0.5847\n",
      "epoch 3\n",
      "Loss: 2647.4460, Epoch: 003, Test: 0.5873\n",
      "epoch 4\n",
      "Loss: 2449.3145, Epoch: 004, Test: 0.5897\n",
      "epoch 5\n",
      "Loss: 2405.0535, Epoch: 005, Test: 0.5918\n",
      "epoch 6\n",
      "Loss: 2425.8374, Epoch: 006, Test: 0.5988\n",
      "epoch 7\n",
      "Loss: 2444.4294, Epoch: 007, Test: 0.6105\n",
      "epoch 8\n",
      "Loss: 2427.1533, Epoch: 008, Test: 0.6224\n",
      "epoch 9\n",
      "Loss: 2393.3848, Epoch: 009, Test: 0.6293\n",
      "epoch 10\n",
      "Loss: 2367.9519, Epoch: 010, Test: 0.6396\n",
      "epoch 11\n",
      "Loss: 2356.4602, Epoch: 011, Test: 0.6509\n",
      "epoch 12\n",
      "Loss: 2354.7366, Epoch: 012, Test: 0.6512\n",
      "epoch 13\n",
      "Loss: 2357.1570, Epoch: 013, Test: 0.6470\n",
      "epoch 14\n",
      "Loss: 2357.8979, Epoch: 014, Test: 0.6460\n",
      "epoch 15\n",
      "Loss: 2353.3877, Epoch: 015, Test: 0.6478\n",
      "epoch 16\n",
      "Loss: 2344.7229, Epoch: 016, Test: 0.6511\n",
      "epoch 17\n",
      "Loss: 2335.7261, Epoch: 017, Test: 0.6550\n",
      "epoch 18\n",
      "Loss: 2329.0950, Epoch: 018, Test: 0.6579\n",
      "epoch 19\n",
      "Loss: 2325.3052, Epoch: 019, Test: 0.6599\n",
      "epoch 20\n",
      "Loss: 2323.6719, Epoch: 020, Test: 0.6612\n",
      "epoch 21\n",
      "Loss: 2323.4065, Epoch: 021, Test: 0.6628\n",
      "epoch 22\n",
      "Loss: 2323.8005, Epoch: 022, Test: 0.6654\n",
      "epoch 23\n",
      "Loss: 2324.2102, Epoch: 023, Test: 0.6697\n",
      "epoch 24\n",
      "Loss: 2324.0857, Epoch: 024, Test: 0.6757\n",
      "epoch 25\n",
      "Loss: 2323.1726, Epoch: 025, Test: 0.6832\n",
      "epoch 26\n",
      "Loss: 2321.6313, Epoch: 026, Test: 0.6918\n",
      "epoch 27\n",
      "Loss: 2319.8538, Epoch: 027, Test: 0.7011\n",
      "epoch 28\n",
      "Loss: 2318.2307, Epoch: 028, Test: 0.7107\n",
      "epoch 29\n",
      "Loss: 2316.9592, Epoch: 029, Test: 0.7203\n",
      "epoch 30\n",
      "Loss: 2316.0515, Epoch: 030, Test: 0.7296\n",
      "epoch 31\n",
      "Loss: 2315.4426, Epoch: 031, Test: 0.7387\n",
      "epoch 32\n",
      "Loss: 2315.0349, Epoch: 032, Test: 0.7474\n",
      "epoch 33\n",
      "Loss: 2314.7441, Epoch: 033, Test: 0.7559\n",
      "epoch 34\n",
      "Loss: 2314.5251, Epoch: 034, Test: 0.7644\n",
      "epoch 35\n",
      "Loss: 2314.3262, Epoch: 035, Test: 0.7733\n",
      "epoch 36\n",
      "Loss: 2314.1311, Epoch: 036, Test: 0.7825\n",
      "epoch 37\n",
      "Loss: 2313.9111, Epoch: 037, Test: 0.7923\n",
      "epoch 38\n",
      "Loss: 2313.6545, Epoch: 038, Test: 0.8027\n",
      "epoch 39\n",
      "Loss: 2313.3655, Epoch: 039, Test: 0.8134\n",
      "epoch 40\n",
      "Loss: 2313.0505, Epoch: 040, Test: 0.8242\n",
      "epoch 41\n",
      "Loss: 2312.7085, Epoch: 041, Test: 0.8348\n",
      "epoch 42\n",
      "Loss: 2312.3523, Epoch: 042, Test: 0.8449\n",
      "epoch 43\n",
      "Loss: 2311.9878, Epoch: 043, Test: 0.8541\n",
      "epoch 44\n",
      "Loss: 2311.6294, Epoch: 044, Test: 0.8623\n",
      "epoch 45\n",
      "Loss: 2311.2654, Epoch: 045, Test: 0.8694\n",
      "epoch 46\n",
      "Loss: 2310.8992, Epoch: 046, Test: 0.8755\n",
      "epoch 47\n",
      "Loss: 2310.5286, Epoch: 047, Test: 0.8807\n",
      "epoch 48\n",
      "Loss: 2310.1455, Epoch: 048, Test: 0.8849\n",
      "epoch 49\n",
      "Loss: 2309.7498, Epoch: 049, Test: 0.8884\n",
      "epoch 50\n",
      "Loss: 2309.3369, Epoch: 050, Test: 0.8911\n",
      "epoch 51\n",
      "Loss: 2308.9109, Epoch: 051, Test: 0.8933\n",
      "epoch 52\n",
      "Loss: 2308.4707, Epoch: 052, Test: 0.8951\n",
      "epoch 53\n",
      "Loss: 2308.0073, Epoch: 053, Test: 0.8964\n",
      "epoch 54\n",
      "Loss: 2307.5334, Epoch: 054, Test: 0.8974\n",
      "epoch 55\n",
      "Loss: 2307.0449, Epoch: 055, Test: 0.8982\n",
      "epoch 56\n",
      "Loss: 2306.5461, Epoch: 056, Test: 0.8988\n",
      "epoch 57\n",
      "Loss: 2306.0310, Epoch: 057, Test: 0.8993\n",
      "epoch 58\n",
      "Loss: 2305.5063, Epoch: 058, Test: 0.8999\n",
      "epoch 59\n",
      "Loss: 2304.9705, Epoch: 059, Test: 0.9004\n",
      "epoch 60\n",
      "Loss: 2304.4248, Epoch: 060, Test: 0.9011\n",
      "epoch 61\n",
      "Loss: 2303.8655, Epoch: 061, Test: 0.9019\n",
      "epoch 62\n",
      "Loss: 2303.2871, Epoch: 062, Test: 0.9028\n",
      "epoch 63\n",
      "Loss: 2302.6982, Epoch: 063, Test: 0.9039\n",
      "epoch 64\n",
      "Loss: 2302.0930, Epoch: 064, Test: 0.9050\n",
      "epoch 65\n",
      "Loss: 2301.4734, Epoch: 065, Test: 0.9062\n",
      "epoch 66\n",
      "Loss: 2300.8354, Epoch: 066, Test: 0.9074\n",
      "epoch 67\n",
      "Loss: 2300.1895, Epoch: 067, Test: 0.9086\n",
      "epoch 68\n",
      "Loss: 2299.5337, Epoch: 068, Test: 0.9096\n",
      "epoch 69\n",
      "Loss: 2298.8672, Epoch: 069, Test: 0.9106\n",
      "epoch 70\n",
      "Loss: 2298.1895, Epoch: 070, Test: 0.9115\n",
      "epoch 71\n",
      "Loss: 2297.5066, Epoch: 071, Test: 0.9123\n",
      "epoch 72\n",
      "Loss: 2296.8171, Epoch: 072, Test: 0.9129\n",
      "epoch 73\n",
      "Loss: 2296.1235, Epoch: 073, Test: 0.9135\n",
      "epoch 74\n",
      "Loss: 2295.4272, Epoch: 074, Test: 0.9141\n",
      "epoch 75\n",
      "Loss: 2294.7183, Epoch: 075, Test: 0.9146\n",
      "epoch 76\n",
      "Loss: 2294.0049, Epoch: 076, Test: 0.9151\n",
      "epoch 77\n",
      "Loss: 2293.2815, Epoch: 077, Test: 0.9157\n",
      "epoch 78\n",
      "Loss: 2292.5515, Epoch: 078, Test: 0.9162\n",
      "epoch 79\n",
      "Loss: 2291.8115, Epoch: 079, Test: 0.9169\n",
      "epoch 80\n",
      "Loss: 2291.0569, Epoch: 080, Test: 0.9175\n",
      "epoch 81\n",
      "Loss: 2290.2932, Epoch: 081, Test: 0.9182\n",
      "epoch 82\n",
      "Loss: 2289.5171, Epoch: 082, Test: 0.9189\n",
      "epoch 83\n",
      "Loss: 2288.7295, Epoch: 083, Test: 0.9196\n",
      "epoch 84\n",
      "Loss: 2287.9285, Epoch: 084, Test: 0.9204\n",
      "epoch 85\n",
      "Loss: 2287.1311, Epoch: 085, Test: 0.9211\n",
      "epoch 86\n",
      "Loss: 2286.3157, Epoch: 086, Test: 0.9219\n",
      "epoch 87\n",
      "Loss: 2285.4922, Epoch: 087, Test: 0.9226\n",
      "epoch 88\n",
      "Loss: 2284.6714, Epoch: 088, Test: 0.9232\n",
      "epoch 89\n",
      "Loss: 2283.8357, Epoch: 089, Test: 0.9238\n",
      "epoch 90\n",
      "Loss: 2282.9939, Epoch: 090, Test: 0.9243\n",
      "epoch 91\n",
      "Loss: 2282.1484, Epoch: 091, Test: 0.9248\n",
      "epoch 92\n",
      "Loss: 2281.2966, Epoch: 092, Test: 0.9253\n",
      "epoch 93\n",
      "Loss: 2280.4382, Epoch: 093, Test: 0.9257\n",
      "epoch 94\n",
      "Loss: 2279.5774, Epoch: 094, Test: 0.9261\n",
      "epoch 95\n",
      "Loss: 2278.7119, Epoch: 095, Test: 0.9265\n",
      "epoch 96\n",
      "Loss: 2277.8457, Epoch: 096, Test: 0.9269\n",
      "epoch 97\n",
      "Loss: 2276.9736, Epoch: 097, Test: 0.9272\n",
      "epoch 98\n",
      "Loss: 2276.0979, Epoch: 098, Test: 0.9275\n",
      "epoch 99\n",
      "Loss: 2275.2183, Epoch: 099, Test: 0.9278\n",
      "Test acc on the last epoch  0.9278462505263552\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device =  torch.device('cpu')# if torch.cuda.is_available() else 'cpu')\n",
    "DeepWalk = {\"Name\": \"DeepWalk\",\"walk_length\":20,\"walks_per_node\":10,\"num_negative_samples\":1,\"context_size\" : 15,\"p\":1,\"q\":1,\"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\" : SamplerRandomWalk } #Проблемы с памятью после того, как увеличила количество тренировочных данных\n",
    "\n",
    "loss = GraphFactorization\n",
    "MO = Main('SAGE', device, loss , mode = 'unsupervised')\n",
    "MO.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My__RW_Neighbour.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
