{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-gN3S4NhAjs",
    "outputId": "fef06879-cb42-4f09-db2d-88671e8c4315"
   },
   "outputs": [],
   "source": [
    "#!pip install -q torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -q --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n",
    "#!pip install -q --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n",
    "#!pip install -q --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n",
    "#!pip install -q --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n",
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "from modules.model import Net\n",
    "from modules.sampling import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = data.x.to(device)\n",
    "y = data.y.squeeze().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=torch.nonzero((data.train_mask == True))\n",
    "indices_of_train_data = ([item for sublist in arr for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborSampler(data.edge_index, node_idx=data.train_mask, batch_size = 256, sizes=[25, 10],\n",
    "                               shuffle=True)\n",
    "def train(model,data,optimizer,PosNegSampler):\n",
    "    model.train()        \n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    if model.mode == 'unsupervised':\n",
    "        if model.conv=='GCN':\n",
    "            out = model.inference(data.to(device))\n",
    "            pos_batch,neg_batch = PosNegSampler.sample(indices_of_train_data)\n",
    "            \n",
    "            loss = model.loss(out[data.train_mask], pos_batch.to(device), neg_batch.to(device))\n",
    "            total_loss+=loss\n",
    "        else:\n",
    "            for batch_size, n_id, adjs in train_loader:\n",
    "                # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
    "                adjs = [adj.to(device) for adj in adjs]\n",
    "                out = model.forward(data.x[n_id].to(device), adjs)\n",
    "                pos_batch,neg_batch = PosNegSampler.sample(list((collections.Counter((adjs[1].edge_index[1]).tolist()).keys())))\n",
    "                loss = model.loss(out, pos_batch.to(device), neg_batch.to(device))\n",
    "                total_loss+=loss\n",
    "        total_loss.backward(retain_graph=True)\n",
    "        optimizer.step()      \n",
    "        return total_loss /len(train_loader)\n",
    "    elif model.mode== 'supervised':\n",
    "        if model.conv=='GCN':\n",
    "            out = model.inference(data.to(device))\n",
    "            loss = model.loss_sup(out[data.train_mask],y[data.train_mask])\n",
    "            total_loss+=loss\n",
    "        else:\n",
    "            for batch_size, n_id, adjs in train_loader:\n",
    "                adjs = [adj.to(device) for adj in adjs]\n",
    "                out = model.forward(data.x[n_id].to(device), adjs)\n",
    "                loss = model.loss_sup(out,y[n_id[:batch_size]])\n",
    "                total_loss+=loss\n",
    "        total_loss.backward(retain_graph=True)\n",
    "        optimizer.step()      \n",
    "        return total_loss /len(train_loader)       \n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,data): \n",
    "    model.eval()\n",
    "    out = model.inference(data.to(device))\n",
    "    y = data.y.squeeze().to(device)\n",
    "    y_true = y.cpu().detach().numpy()\n",
    "    if model.mode == 'supervised':\n",
    "        y_true = y.cpu().unsqueeze(-1)\n",
    "        y_pred = out.cpu().argmax(dim=-1, keepdim=True)\n",
    "        accs = []\n",
    "        for mask in [data.train_mask, data.val_mask, data.test_mask]:    \n",
    "            accs+=[int(y_pred[mask].eq(y_true[mask]).sum()) / int(mask.sum())]\n",
    "        return accs\n",
    "    elif model.mode == 'unsupervised':\n",
    "        clf =MLPClassifier(random_state=1, max_iter=3000)#\n",
    "        clf.fit(out[data.train_mask].cpu().detach().numpy(),y_true[data.train_mask.cpu()])\n",
    "        accs = []\n",
    "        for mask in [data.train_mask,data.val_mask, data.test_mask]:    \n",
    "            accs += [(clf.score(out.cpu().detach()[mask].numpy(), y.cpu().detach()[mask].cpu().numpy()))]\n",
    "        return accs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для начала посмотрим, что получится, если передать только фичи. Без обучения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#в датасете планетоид все фичи это 0 кроме какой-то одной, не уверена, что это актуальное сравнение \n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = y.cpu().detach().numpy()\n",
    "clf = MLPClassifier(random_state=1, max_iter=3000).fit(x[data.train_mask].cpu().detach().numpy(),y_true[data.train_mask])\n",
    "y_pred = clf.predict(x.cpu().detach().numpy())\n",
    "\n",
    "results = []\n",
    "for mask in [data.train_mask, data.val_mask, data.test_mask]:  \n",
    "    results += [(clf.score(x.cpu().detach()[mask].numpy(), y.cpu().detach()[mask].numpy()))]\n",
    "log = 'Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "print(log.format(results[0], results[1], results[2]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь сравним с результатом после обучения эмбедингов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Net(dataset = dataset,mode='supervised',conv='GCN',device=device), Net(dataset = dataset,mode='supervised',conv='GAT',device=device),Net(dataset = dataset,mode='supervised',conv='SAGE',device=device), Net(dataset = dataset,mode='unsupervised',conv='GCN',device=device),Net(dataset = dataset,mode='unsupervised',conv='GAT',device=device),Net(dataset = dataset,mode='unsupervised',conv='SAGE',device=device)]\n",
    "\n",
    "SAGE = {\"Name\":\"SAGE\" , \"walk length\":5,\"walks per node\":50,\"num negative samples\":20,\"context size\" : 10,\"p\":1,\"q\":1, \"loss var\": \"Random Walks\"}\n",
    "DeepWalk = {\"Name\": \"DeepWalk\",\"walk length\":40,\"walks per node\":80,\"num negative samples\":20,\"context size\" : 10,\"p\":1,\"q\":1,\"loss var\": \"Random Walks\" }\n",
    "Node2Vec = {\"Name\": \"Node2Vec\",\"walk length\":100,\"walks per node\":18,\"num negative samples\":20,\"context size\" : 16,\"p\":1.414 ,\"q\":1.414, \"loss var\": \"Random Walks\"}\n",
    "LINE2 = {\"Name\": \"LINE2\",\"C\": \"Adj\",\"num negative samples\":1,\"loss var\": \"Context Matrix\"}\n",
    "VERSE =  {\"Name\": \"VERSE\",\"C\": \"PPR\",\"num negative samples\":1,\"loss var\": \"Context Matrix\"}\n",
    "\n",
    "\n",
    "for Conv in ['SAGE']:\n",
    "    for loss in [VERSE]:\n",
    "        PosNegSampler = Sampler(data,device=device,mask=data.train_mask,loss_info=loss)\n",
    "        model = Net(dataset = dataset,mode='unsupervised',conv=Conv,loss_function=loss[\"loss var\"],device=device)\n",
    "        model.to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "        \n",
    "        losses=[]\n",
    "        train_accs=[]\n",
    "        test_accs=[]\n",
    "        val_accs=[]\n",
    "        name_of_plot='conv: '+model.conv+', mode: '+model.mode+', loss from '+loss[\"Name\"]\n",
    "       \n",
    "        print(name_of_plot)\n",
    "        \n",
    "        for epoch in range(0, 100):\n",
    "            loss = train(model,data,optimizer,PosNegSampler)\n",
    "            losses.append(loss)\n",
    "            train_acc, val_acc, test_acc = test(model,data)\n",
    "            train_accs.append(train_acc)\n",
    "            test_accs.append(test_acc)\n",
    "            val_accs.append(val_acc)\n",
    "            scheduler.step()\n",
    "            #log = 'Loss: {:.4f}, Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "            #print(log.format(loss, epoch, train_acc, val_acc, test_acc))\n",
    "            \n",
    "        print('Validation acc on the last epoch ', val_acc)\n",
    "        plt.plot(losses)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        plt.plot(val_accs)\n",
    "        plt.title(name_of_plot+' validation accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(test_accs)\n",
    "        plt.title(name_of_plot+' test accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My__RW_Neighbour.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
