{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import scipy\n",
    "from scipy.io import loadmat as lm\n",
    "\n",
    "from torch_geometric.utils.convert import  from_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ch = torch.load(\"./data.pt\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 456, 3: 521, 4: 387, 2: 453, 1: 460})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(data_ch.y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = data_Photo.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=list(np.random.randint(0, 5, len(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11751633986928105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08764362531811375"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(y_pred,y_true,average='micro'))\n",
    "f1_score(y_pred,y_true,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18972332015810275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18908907548114942"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(y_true,y_pred,average='micro'))\n",
    "f1_score(y_true,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ПРОБЛЕМЫ ВОПРОСЫ**:\n",
    "- BlogCatalog, CoCit, Wiki имебют матрицу groupб утвреждается что это лейблы но как быть если у BlogCatalog, Wiki на каждую вершину по более чем одному лейблу -  поставила всем как - фичи\n",
    "- Epinion, Arxiv не имеют ни лейблов ни фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_networkx(data, node_attrs=None, edge_attrs=None):\n",
    "    r\"\"\"Converts a data object graph to a networkx graph.\n",
    "\n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): The data object.\n",
    "        node_attrs (iterable of str, optional): The node attributes to be\n",
    "            copied. (default: :obj:`None`)\n",
    "        edge_attrs (iterable of str, optional): The edge attributes to be\n",
    "            copied. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    G = nx.Graph()\n",
    "    if node_attrs is not None:\n",
    "        \n",
    "        for i,attr in enumerate(node_attrs):\n",
    "            G.add_node(i, feature = str(attr.tolist()),label = int(data.y[i]))\n",
    "    else:\n",
    "        G.add_nodes_from(list(range((data.num_nodes))))\n",
    "    \n",
    "    for i, (u, v) in enumerate(data.edge_index.t().tolist()):\n",
    "        G.add_edge(u, v)\n",
    "    \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n"
     ]
    }
   ],
   "source": [
    "#тут мульти-лейбл\n",
    "Blogcatalog = lm('datasets/blogcatalog.mat')\n",
    "blogcatalog_edgeindex,_=from_scipy_sparse_matrix(Blogcatalog['network'])\n",
    "#blogcatalog_x = torch.tensor(scipy.sparse.csr_matrix.toarray(Blogcatalog['group']))\n",
    "data_BlogCatalog = Data(edge_index = blogcatalog_edgeindex)\n",
    "G_BlogCatalog = to_networkx(data_BlogCatalog)\n",
    "#nx.from_scipy_\\sparse_matrix(data_Blogcatalog['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  after removing the cwd from sys.path.\n",
      "WARNING:root:The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n"
     ]
    }
   ],
   "source": [
    "CoCit = lm('datasets/CoCit.mat')\n",
    "CoCit_edgeindex,_=from_scipy_sparse_matrix(CoCit['network'])\n",
    "CoCit_y_matrix = torch.tensor(scipy.sparse.csr_matrix.toarray(CoCit['group']))\n",
    "CoCit_y = CoCit_y_matrix.nonzero().t()[1]\n",
    "data_CoCit = Data(edge_index = CoCit_edgeindex, y = CoCit_y)\n",
    "G_CoCit=to_networkx(data_CoCit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тут мульти-лейбл\n",
    "Wiki = lm('datasets/Wiki.mat')\n",
    "Wiki_edgeindex,_=from_scipy_sparse_matrix(Wiki['network'])\n",
    "#Wiki_x = torch.tensor(scipy.sparse.csr_matrix.toarray(Wiki['group']))\n",
    "data_Wiki = Data(edge_index = Wiki_edgeindex)\n",
    "G_Wiki=to_networkx(data_Wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#провекра на симметричность а значит на ненаправленность\n",
    "np.all(scipy.sparse.csr_matrix.toarray(Blogcatalog['network']).transpose() == scipy.sparse.csr_matrix.toarray(Blogcatalog['network']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#провекра на симметричность а значит на ненаправленность\n",
    "np.all(scipy.sparse.csr_matrix.toarray(CoCit['network']).transpose() == scipy.sparse.csr_matrix.toarray(CoCit['network']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#провекра на симметричность а значит на ненаправленность\n",
    "np.all(scipy.sparse.csr_matrix.toarray(Wiki['network']).transpose() == scipy.sparse.csr_matrix.toarray(Wiki['network']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/soc-Epinions1.txt','r') as f:\n",
    "    data_Epinion = f.readlines()\n",
    "\n",
    "new_list=list(map(lambda x: x.split('\\t'),data_Epinion[4:]))\n",
    "#print(new_list)\n",
    "dataedge_ep = list(map(lambda x: [int(x[0]),int(x[1].split('\\n')[0])],new_list))\n",
    "set1=set(collections.Counter((np.array(dataedge_ep)).transpose()[1]).keys()) | set(collections.Counter((np.array(dataedge_ep)).transpose()[0]).keys())\n",
    "map_ep={}\n",
    "for j,i in enumerate(set1):\n",
    "    map_ep[i] = j\n",
    "dataedge_ep_new = list(map(lambda x: [map_ep[x[0]],map_ep[x[1]]], dataedge_ep))\n",
    "data_edge_index_Epinion = torch.tensor(dataedge_ep_new).t()\n",
    "data_Epinion_torch = Data(edge_index=data_edge_index_Epinion)\n",
    "G_Epinion = to_networkx(data_Epinion_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/CA-GrQc.txt','r') as f:\n",
    "    data_Arxiv = f.readlines()\n",
    "\n",
    "new_list=list(map(lambda x: x.split('\\t'),data_Arxiv[4:]))\n",
    "#print(new_list)\n",
    "dataedge = list(map(lambda x: [int(x[0]),int(x[1].split('\\n')[0])],new_list))\n",
    "set2=set(collections.Counter((np.array(dataedge)).transpose()[1]).keys()) | set(collections.Counter((np.array(dataedge)).transpose()[0]).keys())\n",
    "map_ar={}\n",
    "for j,i in enumerate(set2):\n",
    "    map_ar[i] = j\n",
    "    \n",
    "dataedge_ar_new = list(map(lambda x: [map_ar[x[0]],map_ar[x[1]]], dataedge))\n",
    "\n",
    "data_edge_index_Arxiv = torch.tensor(dataedge_ar_new).t()\n",
    "data_Arxiv_torch = Data(edge_index=data_edge_index_Arxiv)\n",
    "G_Arxiv = to_networkx(data_Arxiv_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "data_Cora =Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())[0]\n",
    "#data_cora =dataset[0]\n",
    "data_Citeseer =Planetoid(root='/tmp/Citeseer', name='Citeseer',transform=T.NormalizeFeatures())[0]\n",
    "data_Pubmed =Planetoid(root='/tmp/Pubmed', name='Pubmed',transform=T.NormalizeFeatures())[0]\n",
    "\n",
    "from torch_geometric.datasets import Amazon\n",
    "\n",
    "data_Photo =Amazon(root='/tmp/Photo', name='Photo',transform=T.NormalizeFeatures())[0]\n",
    "data_Computers =Amazon(root='/tmp/Computers', name='Computers',transform=T.NormalizeFeatures())[0]\n",
    "\n",
    "from torch_geometric.datasets import Coauthor\n",
    "\n",
    "data_CS =Coauthor(root='/tmp/CS', name='CS',transform=T.NormalizeFeatures())[0]\n",
    "data_Physics =Coauthor(root='/tmp/Physics', name='Physics',transform=T.NormalizeFeatures())[0]\n",
    "\n",
    "from torch_geometric.datasets import Reddit\n",
    "\n",
    "\n",
    "#social networks: Reddit, Flickr\n",
    "from torch_geometric.datasets import Flickr\n",
    "data_Flickr =Flickr(root='/tmp/Flickr',transform=T.NormalizeFeatures())[0]\n",
    "# data_Reddit = Reddit(root='/tmp/Reddit',transform=T.NormalizeFeatures()) очень тяжелый \n",
    "\n",
    "\n",
    "from torch_geometric.datasets import PPI\n",
    "\n",
    "data_PPI = PPI(root='/tmp/PPI', split=\"train\",transform=T.NormalizeFeatures())[0] #тут только train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_CoCit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-73aa4980f75a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata_Cora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_Citeseer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_Pubmed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_Photo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_Computers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_CS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_Physics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_Flickr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_CoCit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_BlogCatalog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_Wiki\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_Arxiv_torch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_Epinion_torch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdatasets_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Cora'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Citeseer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pubmed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Photo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Computers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Physics'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Flickr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CoCit'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'BlogCatalog'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Wikipedia'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Arxiv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Epinion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_CoCit' is not defined"
     ]
    }
   ],
   "source": [
    "datasets = [data_Cora, data_Citeseer, data_Pubmed, data_Photo, data_Computers, data_CS, data_Physics,data_Flickr,data_CoCit,data_BlogCatalog,data_Wiki,data_Arxiv_torch,data_Epinion_torch]\n",
    "datasets_names = ['Cora', 'Citeseer', 'Pubmed', 'Photo', 'Computers', 'CS', 'Physics','Flickr','CoCit','BlogCatalog','Wikipedia','Arxiv','Epinion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "for dataset in datasets:\n",
    "    graphs.append(to_networkx(dataset,dataset.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets =[data_Cora, data_Citeseer,  data_Photo, data_Arxiv_torch]\n",
    "datasets_names = ['Cora','Citeseer','Photo','Arxiv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_graph = to_networkx(data_Cora,data_Cora.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chameleon_graph = to_networkx(data_ch,data_ch.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27463230751013357\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "mean_1=0\n",
    "mean_2=0\n",
    "for edge in chameleon_graph.edges():\n",
    "    mean_1 +=  chameleon_graph.nodes('label')[edge[0]]\n",
    "    mean_2 += chameleon_graph.nodes('label')[edge[1]]\n",
    "mean_1 = mean_1/len( chameleon_graph.edges())\n",
    "mean_2 = mean_2/len( chameleon_graph.edges())\n",
    "\n",
    "for edge in chameleon_graph.edges():\n",
    "    one+= (chameleon_graph.nodes('label')[edge[0]]-mean_1)*(chameleon_graph.nodes('label')[edge[1]]-mean_2)\n",
    "    two += (chameleon_graph.nodes('label')[edge[0]]-mean_1)*(chameleon_graph.nodes('label')[edge[0]]-mean_1)\n",
    "    three += (chameleon_graph.nodes('label')[edge[1]]-mean_2)*(chameleon_graph.nodes('label')[edge[1]]-mean_2)\n",
    "\n",
    "d = math.sqrt(two*three)\n",
    "print(one/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6840364066412794\n"
     ]
    }
   ],
   "source": [
    "citeseer_graph = to_networkx(data_Citeseer,data_Citeseer.x)\n",
    "import math\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "mean_1=0\n",
    "mean_2=0\n",
    "for edge in citeseer_graph.edges():\n",
    "    mean_1 +=  citeseer_graph.nodes('label')[edge[0]]\n",
    "    mean_2 += citeseer_graph.nodes('label')[edge[1]]\n",
    "mean_1 = mean_1/len( citeseer_graph.edges())\n",
    "mean_2 = mean_2/len( citeseer_graph.edges())\n",
    "\n",
    "for edge in citeseer_graph.edges():\n",
    "    one+= (citeseer_graph.nodes('label')[edge[0]]-mean_1)*(citeseer_graph.nodes('label')[edge[1]]-mean_2)\n",
    "    two += (citeseer_graph.nodes('label')[edge[0]]-mean_1)*(citeseer_graph.nodes('label')[edge[0]]-mean_1)\n",
    "    three += (citeseer_graph.nodes('label')[edge[1]]-mean_2)*(citeseer_graph.nodes('label')[edge[1]]-mean_2)\n",
    "\n",
    "d = math.sqrt(two*three)\n",
    "print(one/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8539507520546509\n"
     ]
    }
   ],
   "source": [
    "photo_graph = to_networkx(data_Photo,data_Photo.x)\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "mean_1=0\n",
    "mean_2=0\n",
    "for edge in photo_graph.edges():\n",
    "    mean_1 +=  photo_graph.nodes('label')[edge[0]]\n",
    "    mean_2 += photo_graph.nodes('label')[edge[1]]\n",
    "mean_1 = mean_1/len( photo_graph.edges())\n",
    "mean_2 = mean_2/len( photo_graph.edges())\n",
    "\n",
    "for edge in photo_graph.edges():\n",
    "    one+= (photo_graph.nodes('label')[edge[0]]-mean_1)*(photo_graph.nodes('label')[edge[1]]-mean_2)\n",
    "    two += (photo_graph.nodes('label')[edge[0]]-mean_1)*(photo_graph.nodes('label')[edge[0]]-mean_1)\n",
    "    three += (photo_graph.nodes('label')[edge[1]]-mean_2)*(photo_graph.nodes('label')[edge[1]]-mean_2)\n",
    "\n",
    "d = math.sqrt(two*three)\n",
    "print(one/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "mean_1=0\n",
    "mean_2=0\n",
    "for edge in cora_graph.edges():\n",
    "    mean_1 +=  cora_graph.nodes('label')[edge[0]]\n",
    "    mean_2 += cora_graph.nodes('label')[edge[1]]\n",
    "mean_1 = mean_1/len( cora_graph.edges())\n",
    "mean_2 = mean_2/len( cora_graph.edges())\n",
    "\n",
    "for edge in cora_graph.edges():\n",
    "    one+= (cora_graph.nodes('label')[edge[0]]-mean_1)*(cora_graph.nodes('label')[edge[1]]-mean_2)\n",
    "    two += (cora_graph.nodes('label')[edge[0]]-mean_1)*(cora_graph.nodes('label')[edge[0]]-mean_1)\n",
    "    three += (cora_graph.nodes('label')[edge[1]]-mean_2)*(cora_graph.nodes('label')[edge[1]]-mean_2)\n",
    "\n",
    "d = math.sqrt(two*three)\n",
    "print(one/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attribute_assort = []\n",
    "label_assort = []\n",
    "degree_assort = []\n",
    "density = []\n",
    "clustering_coef  = []\n",
    "avg_degree=[]    \n",
    "if True:\n",
    "        gr = chameleon_graph\n",
    "        \n",
    "        try:\n",
    "            i_d=(data_ch.is_directed())\n",
    "            isdirected=(i_d)\n",
    "        except:\n",
    "            print('no info')\n",
    "        \n",
    "        try:\n",
    "            a_s = nx.attribute_assortativity_coefficient(gr,'feature')\n",
    "            attribute_assort.append(a_s)\n",
    "        except:\n",
    "            attribute_assort.append(None)\n",
    "        \n",
    "            \n",
    "        density.append(nx.density(gr))\n",
    "             #ассортативность\n",
    "        degree_assort.append(nx.degree_assortativity_coefficient(gr))\n",
    "        clustering_coef.append(np.mean(list(nx.clustering(gr).values())))\n",
    "        avg_degree.append(np.mean(np.array(list(dict(gr.degree).values()))))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "number_of_nodes = []\n",
    "clustering_coef=[]\n",
    "density=[]\n",
    "degree_assort=[]\n",
    "number_of_features=[]\n",
    "number_of_labels = []\n",
    "attribute_assort = []\n",
    "isdirected=[]\n",
    "avg_degree = []\n",
    "avg_path = []\n",
    " \n",
    "    \n",
    "for i,gr in enumerate(graphs):\n",
    "        print(i)\n",
    "        try:\n",
    "            n_f=datasets[i].num_features\n",
    "            number_of_features.append(n_f)\n",
    "        except:\n",
    "            if (datasets_names[i] == 'CoCit') or (datasets_names[i]=='BlogCatalog') or (datasets_names[i]=='Wikipedia'):\n",
    "                number_of_features.append(datasets[i].shape(1))\n",
    "            else:\n",
    "                number_of_features.append(0)\n",
    "        \n",
    "        try:\n",
    "            i_d=(datasets[i].is_directed())\n",
    "            isdirected.append(i_d)\n",
    "        except:\n",
    "            if (datasets_names[i] == 'CoCit') or (datasets_names[i]=='BlogCatalog') or (datasets_names[i]=='Wikipedia'):\n",
    "                isdirected.append(False)\n",
    "            elif (datasets_names[i] == 'Arxiv') or (datasets_names[i]=='Epinion'):\n",
    "                isdirected.append(True)\n",
    "        \n",
    "        try:\n",
    "            n_l = len(collections.Counter(datasets[i].y.tolist()).keys())\n",
    "            number_of_labels.append(n_l)\n",
    "        except:\n",
    "            if (datasets_names[i] == 'CoCit'):\n",
    "                number_of_labels.append(len(collections.Counter(datasets[i].y).keys()))\n",
    "            elif (datasets_names[i] == 'Arxiv') or (datasets_names[i]=='Epinion') or (datasets_names[i]=='BlogCatalog') or (datasets_names[i]=='Wikipedia'):\n",
    "                number_of_labels.append(None)\n",
    "        \n",
    "        try:\n",
    "            a_s = nx.attribute_assortativity_coefficient(gr,'feature')\n",
    "            attribute_assort.append(a_s)\n",
    "        except:\n",
    "            attribute_assort.append(None)\n",
    "        \n",
    "            \n",
    "        number_of_nodes.append(gr.number_of_nodes())\n",
    "            #плотность\n",
    "        density.append(nx.density(gr))\n",
    "             #ассортативность\n",
    "        degree_assort.append(nx.degree_assortativity_coefficient(gr))\n",
    "        clustering_coef.append(np.mean(list(nx.clustering(gr).values())))\n",
    "        avg_degree.append(np.mean(np.array(list(dict(graphs[1].degree).values()))))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets =[data_Cora, data_Citeseer, data_Pubmed, data_Photo, data_Computers]\n",
    "datasets_names = ['Cora','Citeseer','Pubmed','Photo','Computers']\n",
    "gr=graphs[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-548539492dd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnected_components\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mep\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage_shortest_path_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anpolol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\generic.py\u001b[0m in \u001b[0;36maverage_shortest_path_length\u001b[1;34m(G, weight, method)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msingle_source_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;31m# Sum the distances for each (ordered) pair of source and target node.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"floyd-warshall\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anpolol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\generic.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msingle_source_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;31m# Sum the distances for each (ordered) pair of source and target node.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"floyd-warshall\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anpolol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\generic.py\u001b[0m in \u001b[0;36mpath_length\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpath_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"unweighted\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_source_shortest_path_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"dijkstra\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_source_dijkstra_path_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anpolol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py\u001b[0m in \u001b[0;36msingle_source_shortest_path_length\u001b[1;34m(G, source, cutoff)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mcutoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mnextlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_single_shortest_path_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnextlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anpolol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py\u001b[0m in \u001b[0;36m_single_shortest_path_length\u001b[1;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mnextlevel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mseen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anpolol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\networkx\\classes\\coreviews.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode_ok_shorter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_atlas\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anpolol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\networkx\\classes\\coreviews.py\u001b[0m in \u001b[0;36mnew_node_ok\u001b[1;34m(nbr)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mnew_node_ok\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEDGE_OK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mFilterAtlas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_node_ok\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anpolol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\networkx\\classes\\filters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for g in gr:\n",
    "    ep=0\n",
    "    n=0\n",
    "    for component in (nx.connected_components(g)):\n",
    "        ep+=nx.average_shortest_path_length(g.subgraph(component))\n",
    "        n+=1\n",
    "        print(ep)\n",
    "    print('for gr, ', (ep/(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "            ep = nx.average_shortest_path_length(gr)\n",
    "            avg_path.append(ep)\n",
    "        except:\n",
    "            ep = 0\n",
    "            n = 0\n",
    "            for component in (nx.connected_components(gr)):\n",
    "                ep+=nx.average_shortest_path_length(gr.subgraph(component))\n",
    "                n+=1\n",
    "            avg_path.append(ep/(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_path = [1.170483515230952, 1.0880632688377956, 6.336870027999047, 0.17807105484562516, 0.12205409485326828]#, 5.427693716383878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of dataset</th>\n",
       "      <th>Number of nodes (NN)</th>\n",
       "      <th>Number of features (NF)</th>\n",
       "      <th>Number of lables (NL)</th>\n",
       "      <th>Directed?</th>\n",
       "      <th>Clustering coefficient (CC)</th>\n",
       "      <th>Density(D)</th>\n",
       "      <th>Degree assortativity coefficient(DAC)</th>\n",
       "      <th>Attribute assortativity coefficient(AAC)</th>\n",
       "      <th>Average Degree (AD)</th>\n",
       "      <th>Average shortest path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cora</td>\n",
       "      <td>2708</td>\n",
       "      <td>1433</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0.240673</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>-0.065871</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>3.898080</td>\n",
       "      <td>1.170484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Citeseer</td>\n",
       "      <td>3327</td>\n",
       "      <td>3703</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.141471</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.048378</td>\n",
       "      <td>-0.000547</td>\n",
       "      <td>2.736399</td>\n",
       "      <td>1.088063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photo</td>\n",
       "      <td>7650</td>\n",
       "      <td>745</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.403979</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>-0.044943</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>31.132288</td>\n",
       "      <td>0.178071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computers</td>\n",
       "      <td>13752</td>\n",
       "      <td>767</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.344126</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>-0.056488</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>35.756399</td>\n",
       "      <td>0.122054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pubmed</td>\n",
       "      <td>19717</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.060175</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>-0.043640</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>4.496019</td>\n",
       "      <td>6.336870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name of dataset  Number of nodes (NN)  Number of features (NF)  \\\n",
       "0            Cora                  2708                     1433   \n",
       "1        Citeseer                  3327                     3703   \n",
       "3           Photo                  7650                      745   \n",
       "4       Computers                 13752                      767   \n",
       "2          Pubmed                 19717                      500   \n",
       "\n",
       "   Number of lables (NL)  Directed?   Clustering coefficient (CC)  Density(D)  \\\n",
       "0                      7       False                     0.240673    0.001440   \n",
       "1                      6       False                     0.141471    0.000823   \n",
       "3                      8       False                     0.403979    0.004070   \n",
       "4                     10       False                     0.344126    0.002600   \n",
       "2                      3       False                     0.060175    0.000228   \n",
       "\n",
       "   Degree assortativity coefficient(DAC)  \\\n",
       "0                              -0.065871   \n",
       "1                               0.048378   \n",
       "3                              -0.044943   \n",
       "4                              -0.056488   \n",
       "2                              -0.043640   \n",
       "\n",
       "   Attribute assortativity coefficient(AAC)  Average Degree (AD)  \\\n",
       "0                                 -0.000850             3.898080   \n",
       "1                                 -0.000547             2.736399   \n",
       "3                                 -0.000427            31.132288   \n",
       "4                                 -0.000332            35.756399   \n",
       "2                                 -0.000189             4.496019   \n",
       "\n",
       "   Average shortest path  \n",
       "0               1.170484  \n",
       "1               1.088063  \n",
       "3               0.178071  \n",
       "4               0.122054  \n",
       "2               6.336870  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name of dataset' : datasets_names,\n",
    "                                'Number of nodes (NN)' :number_of_nodes,'Number of features (NF)' :number_of_features,'Number of lables (NL)':number_of_labels , 'Directed? ' :isdirected,\n",
    "                                'Clustering coefficient (CC)': clustering_coef,'Density(D)':density, 'Degree assortativity coefficient(DAC)':degree_assort, 'Attribute assortativity coefficient(AAC)': attribute_assort, 'Average Degree (AD)': avg_degree, 'Average shortest path': avg_path })\n",
    "df.sort_values(by=['Attribute assortativity coefficient(AAC)']) #добавить атрибуты, направленность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('analytics.pickle','wb') as f:\n",
    "    pickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Pearson degree assortativity coefficient (PDAC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Degree assortativity coefficient(DAC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(datasets[i].x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
