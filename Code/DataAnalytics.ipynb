{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] Не найдена указанная процедура",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cfb973f07c50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch_geometric\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch_geometric\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtemporal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTemporalData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0min_memory_dataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m from torch_geometric.utils import (contains_isolated_nodes,\n\u001b[0;32m     10\u001b[0m                                    contains_self_loops, is_undirected)\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch_sparse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m ]:\n\u001b[0;32m     14\u001b[0m     torch.ops.load_library(importlib.machinery.PathFinder().find_spec(\n\u001b[1;32m---> 15\u001b[1;33m         f'{library}_{suffix}', [osp.dirname(__file__)]).origin)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;31m# operators with the JIT.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] Не найдена указанная процедура"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import scipy\n",
    "from scipy.io import loadmat as lm\n",
    "\n",
    "from torch_geometric.utils.convert import  from_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ПРОБЛЕМЫ ВОПРОСЫ**:\n",
    "- BlogCatalog, CoCit, Wiki имебют матрицу groupб утвреждается что это лейблы но как быть если у BlogCatalog, Wiki на каждую вершину по более чем одному лейблу -  поставила всем как - фичи\n",
    "- Epinion, Arxiv не имеют ни лейблов ни фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_networkx(data, node_attrs=None, edge_attrs=None):\n",
    "    r\"\"\"Converts a data object graph to a networkx graph.\n",
    "\n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): The data object.\n",
    "        node_attrs (iterable of str, optional): The node attributes to be\n",
    "            copied. (default: :obj:`None`)\n",
    "        edge_attrs (iterable of str, optional): The edge attributes to be\n",
    "            copied. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    G = nx.Graph()\n",
    "    if node_attrs is not None:\n",
    "        \n",
    "        for i,attr in enumerate(node_attrs):\n",
    "            G.add_node(i, feature = str(attr.tolist()))\n",
    "    else:\n",
    "        G.add_nodes_from(list(range((data.num_nodes))))\n",
    "    \n",
    "    for i, (u, v) in enumerate(data.edge_index.t().tolist()):\n",
    "        G.add_edge(u, v)\n",
    "    \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тут мульти-лейбл\n",
    "Blogcatalog = lm('datasets/blogcatalog.mat')\n",
    "blogcatalog_edgeindex,_=from_scipy_sparse_matrix(Blogcatalog['network'])\n",
    "#blogcatalog_x = torch.tensor(scipy.sparse.csr_matrix.toarray(Blogcatalog['group']))\n",
    "data_BlogCatalog = Data(edge_index = blogcatalog_edgeindex)\n",
    "G_BlogCatalog = to_networkx(data_BlogCatalog)\n",
    "#nx.from_scipy_\\sparse_matrix(data_Blogcatalog['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoCit = lm('datasets/CoCit.mat')\n",
    "CoCit_edgeindex,_=from_scipy_sparse_matrix(CoCit['network'])\n",
    "CoCit_y_matrix = torch.tensor(scipy.sparse.csr_matrix.toarray(CoCit['group']))\n",
    "CoCit_y = CoCit_y_matrix.nonzero().t()[1]\n",
    "data_CoCit = Data(edge_index = CoCit_edgeindex, y = CoCit_y)\n",
    "G_CoCit=to_networkx(data_CoCit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тут мульти-лейбл\n",
    "Wiki = lm('datasets/Wiki.mat')\n",
    "Wiki_edgeindex,_=from_scipy_sparse_matrix(Wiki['network'])\n",
    "#Wiki_x = torch.tensor(scipy.sparse.csr_matrix.toarray(Wiki['group']))\n",
    "data_Wiki = Data(edge_index = Wiki_edgeindex)\n",
    "G_Wiki=to_networkx(data_Wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#провекра на симметричность а значит на ненаправленность\n",
    "np.all(scipy.sparse.csr_matrix.toarray(Blogcatalog['network']).transpose() == scipy.sparse.csr_matrix.toarray(Blogcatalog['network']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#провекра на симметричность а значит на ненаправленность\n",
    "np.all(scipy.sparse.csr_matrix.toarray(CoCit['network']).transpose() == scipy.sparse.csr_matrix.toarray(CoCit['network']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#провекра на симметричность а значит на ненаправленность\n",
    "np.all(scipy.sparse.csr_matrix.toarray(Wiki['network']).transpose() == scipy.sparse.csr_matrix.toarray(Wiki['network']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/soc-Epinions1.txt','r') as f:\n",
    "    data_Epinion = f.readlines()\n",
    "\n",
    "new_list=list(map(lambda x: x.split('\\t'),data_Epinion[4:]))\n",
    "#print(new_list)\n",
    "dataedge_ep = list(map(lambda x: [int(x[0]),int(x[1].split('\\n')[0])],new_list))\n",
    "set1=set(collections.Counter((np.array(dataedge_ep)).transpose()[1]).keys()) | set(collections.Counter((np.array(dataedge_ep)).transpose()[0]).keys())\n",
    "map_ep={}\n",
    "for j,i in enumerate(set1):\n",
    "    map_ep[i] = j\n",
    "dataedge_ep_new = list(map(lambda x: [map_ep[x[0]],map_ep[x[1]]], dataedge_ep))\n",
    "data_edge_index_Epinion = torch.tensor(dataedge_ep_new).t()\n",
    "data_Epinion_torch = Data(edge_index=data_edge_index_Epinion)\n",
    "G_Epinion = to_networkx(data_Epinion_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/CA-GrQc.txt','r') as f:\n",
    "    data_Arxiv = f.readlines()\n",
    "\n",
    "new_list=list(map(lambda x: x.split('\\t'),data_Arxiv[4:]))\n",
    "#print(new_list)\n",
    "dataedge = list(map(lambda x: [int(x[0]),int(x[1].split('\\n')[0])],new_list))\n",
    "set2=set(collections.Counter((np.array(dataedge)).transpose()[1]).keys()) | set(collections.Counter((np.array(dataedge)).transpose()[0]).keys())\n",
    "map_ar={}\n",
    "for j,i in enumerate(set2):\n",
    "    map_ar[i] = j\n",
    "    \n",
    "dataedge_ar_new = list(map(lambda x: [map_ar[x[0]],map_ar[x[1]]], dataedge))\n",
    "\n",
    "data_edge_index_Arxiv = torch.tensor(dataedge_ar_new).t()\n",
    "data_Arxiv_torch = Data(edge_index=data_edge_index_Arxiv)\n",
    "G_Arxiv = to_networkx(data_Arxiv_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "data_Cora =Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())[0]\n",
    "#data_cora =dataset[0]\n",
    "data_Citeseer =Planetoid(root='/tmp/Citeseer', name='Citeseer',transform=T.NormalizeFeatures())[0]\n",
    "data_Pubmed =Planetoid(root='/tmp/Pubmed', name='Pubmed',transform=T.NormalizeFeatures())[0]\n",
    "\n",
    "from torch_geometric.datasets import Amazon\n",
    "\n",
    "data_Photo =Amazon(root='/tmp/Photo', name='Photo',transform=T.NormalizeFeatures())[0]\n",
    "data_Computers =Amazon(root='/tmp/Computers', name='Computers',transform=T.NormalizeFeatures())[0]\n",
    "\n",
    "from torch_geometric.datasets import Coauthor\n",
    "\n",
    "data_CS =Coauthor(root='/tmp/CS', name='CS',transform=T.NormalizeFeatures())[0]\n",
    "data_Physics =Coauthor(root='/tmp/Physics', name='Physics',transform=T.NormalizeFeatures())[0]\n",
    "\n",
    "from torch_geometric.datasets import Reddit\n",
    "\n",
    "\n",
    "#social networks: Reddit, Flickr\n",
    "from torch_geometric.datasets import Flickr\n",
    "data_Flickr =Flickr(root='/tmp/Flickr',transform=T.NormalizeFeatures())[0]\n",
    "# data_Reddit = Reddit(root='/tmp/Reddit',transform=T.NormalizeFeatures()) очень тяжелый \n",
    "\n",
    "\n",
    "from torch_geometric.datasets import PPI\n",
    "\n",
    "data_PPI = PPI(root='/tmp/PPI', split=\"train\",transform=T.NormalizeFeatures())[0] #тут только train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [data_Cora, data_Citeseer, data_Pubmed, data_Photo, data_Computers, data_CS, data_Physics,data_Flickr,data_CoCit,data_BlogCatalog,data_Wiki,data_Arxiv_torch,data_Epinion_torch]\n",
    "datasets_names = ['Cora', 'Citeseer', 'Pubmed', 'Photo', 'Computers', 'CS', 'Physics','Flickr','CoCit','BlogCatalog','Wikipedia','Arxiv','Epinion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for dataset in datasets[:8]:\n",
    "    graphs.append(to_networkx(dataset,dataset.x))\n",
    "for dataset in datasets[8:]:\n",
    "    graphs.append(to_networkx(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,gr in enumerate(graphs):\n",
    "    if nx.number_connected_components(graphs[i]) == 1:\n",
    "        print(i,datasets_names[i])\n",
    "#2,5,6,7,9,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nodes = []\n",
    "clustering_coef=[]\n",
    "density=[]\n",
    "degree_assort=[]\n",
    "number_of_features=[]\n",
    "number_of_labels = []\n",
    "attribute_assort = []\n",
    "isdirected=[]\n",
    "avg_degree = []\n",
    "avg_path = []\n",
    " \n",
    "    \n",
    "for i,gr in enumerate(graphs):\n",
    "        print(i)\n",
    "        try:\n",
    "            n_f=datasets[i].num_features\n",
    "            number_of_features.append(n_f)\n",
    "        except:\n",
    "            if (datasets_names[i] == 'CoCit') or (datasets_names[i]=='BlogCatalog') or (datasets_names[i]=='Wikipedia'):\n",
    "                number_of_features.append(datasets[i].shape(1))\n",
    "            else:\n",
    "                number_of_features.append(0)\n",
    "        \n",
    "        try:\n",
    "            i_d=(datasets[i].is_directed())\n",
    "            isdirected.append(i_d)\n",
    "        except:\n",
    "            if (datasets_names[i] == 'CoCit') or (datasets_names[i]=='BlogCatalog') or (datasets_names[i]=='Wikipedia'):\n",
    "                isdirected.append(False)\n",
    "            elif (datasets_names[i] == 'Arxiv') or (datasets_names[i]=='Epinion'):\n",
    "                isdirected.append(True)\n",
    "        \n",
    "        try:\n",
    "            n_l = len(collections.Counter(datasets[i].y.tolist()).keys())\n",
    "            number_of_labels.append(n_l)\n",
    "        except:\n",
    "            if (datasets_names[i] == 'CoCit'):\n",
    "                number_of_labels.append(len(collections.Counter(datasets[i].y).keys()))\n",
    "            elif (datasets_names[i] == 'Arxiv') or (datasets_names[i]=='Epinion') or (datasets_names[i]=='BlogCatalog') or (datasets_names[i]=='Wikipedia'):\n",
    "                number_of_labels.append(None)\n",
    "        \n",
    "        try:\n",
    "            a_s = nx.attribute_assortativity_coefficient(gr,'feature')\n",
    "            attribute_assort.append(a_s)\n",
    "        except:\n",
    "            attribute_assort.append(None)\n",
    "        \n",
    "            \n",
    "        number_of_nodes.append(gr.number_of_nodes())\n",
    "            #плотность\n",
    "        density.append(nx.density(gr))\n",
    "             #ассортативность\n",
    "        degree_assort.append(nx.degree_assortativity_coefficient(gr))\n",
    "        clustering_coef.append(np.mean(list(nx.clustering(gr).values())))\n",
    "        avg_degree.append(np.mean(np.array(list(dict(graphs[1].degree).values()))))\n",
    "        \n",
    "        try:\n",
    "            ep = nx.average_shortest_path_length(gr)\n",
    "            avg_path.append(ep)\n",
    "        except:\n",
    "            ep = 0\n",
    "            n = 0\n",
    "            for component in (nx.connected_components(gr)):\n",
    "                ep+=nx.average_shortest_path_length(gr.subgraph(component))\n",
    "                n+=1\n",
    "            avg_path.append(ep/(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nodes = []\n",
    "clustering_coef=[]\n",
    "density=[]\n",
    "degree_assort=[]\n",
    "number_of_features=[]\n",
    "number_of_labels = []\n",
    "attribute_assort = []\n",
    "isdirected=[]\n",
    "avg_degree = []\n",
    "avg_path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Name of dataset' : datasets_names,\n",
    "                                'Number of nodes (NN)' :number_of_nodes,'Number of features (NF)' :number_of_features,'Number of lables (NL)':number_of_labels , 'Directed? ' :isdirected,\n",
    "                                'Clustering coefficient (CC)': clustering_coef,'Density(D)':density, 'Degree assortativity coefficient(DAC)':degree_assort, 'Attribute assortativity coefficient(AAC)': attribute_assort, 'Average Degree (AD)': avg_degree, 'Average shortest path': avg_path })\n",
    "df.sort_values(by=['Attribute assortativity coefficient(AAC)']) #добавить атрибуты, направленность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('analytics.pickle','wb') as f:\n",
    "    pickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Pearson degree assortativity coefficient (PDAC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Degree assortativity coefficient(DAC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(datasets[i].x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
