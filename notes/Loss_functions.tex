\documentclass[11pt, titlepackage]{article}
\usepackage[left=3cm, right=3cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{cite}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx} 
\usepackage{indentfirst}
\usepackage{multirow}
\usepackage{footnote}
\usepackage{longtable}
\usepackage{array}
\usepackage{caption,tabularx,booktabs}
\usepackage{tikz} 
\usepackage{longtable}
\usepackage{amsmath}
% переименовываем  список литературы в "список используемой литературы"
\addto\captionsrussian{\def\refname{\centering Список используемых источников}}
\title{Функции потерь}
\author{}
\date{}

\begin{document}
\maketitle

\newpage


\begin{center}
			{\section{Необходимые обозначения}}
		\end{center}
\begin{table}[h!]
\caption{\label{tab:notation}Необходимые обозначения}
\begin{center}
\begin{tabular}{|l|p{300pt}|}
\hline
Обозначение & Расшифровка \\
\hline
 $G=(V,E)$ & Граф \\
 $V =\{ v_i\}$& непустое множество вершин\\
$|V| = n$ & Количество вершин в графе \\
$E = \{ e_{ij}\}$& множество пар веришин, называемых ребрами\\
$e_{ij}$& это реберо между вершиными $v_i$ и $v_j$\\
$|E| = m$ & Количество рёбер в графе \\
$\textbf{A}=\{ a_{ij}\}$ & Матрица смежности \\
\textbf{I} & Единичная матрица \\
\textbf{D} & Матрица степеней вершин графа \\
\textbf{P} = $\textbf{D}^{-1}\textbf{A}$ & Матрица переходов \\
$\textbf{C} = \{c_{i,j}\}$ & Матрица схожести вершин. В простом случае $\textbf{C}=\textbf{A}$ \\

\hline
$r$ & Размерность признакового пространства\\
 $\textbf{X} $   & Матрица признаков вершин, размерностью $n\times r$ \\
\hline
$\mathcal{L} $ & Функция потерь \\
\hline
$d$ & Размерность эмбедингов\\
$\Phi, \Theta$ & Матрицы эмбедингов, размерностью $n \times d$ \\
$\Phi_i, \Theta_i$ & Ряд в матрицах эмбедингов. Исходный и контекстный эмбединги вершины $v_i$ \\
\hline
$N(v)$ &  Соседи вершины $v$ внутри окна определенного размера последовательности случайного блуждания \\
\hline
\end{tabular}
\end{center}
\end{table} 

\newpage
\begin{center}
{\section{Таблица с функциями потерь}}
\end{center}

\begin{table}[ph]
\caption{\label{tab:methods}Методы неконтролируемого обучения}
\setlength{\extrarowheight}{10pt}
\begin{tabular}{|p{60pt}|p{60pt}|p{180pt}|p{110pt}|}
\hline
 Метод & Контекстный эмбединг  & Функция потерь & Подходы к оптимизации, используемые методы \\
\hline
 Laplacian EigenMaps & $\times$  & $ \frac{1}{2} \sum_{i,j} |\Phi_i - \Phi_j|^2 a_{i,j} $ & Matrix Factorization\\
\hline
 Graph Factorization & $\times$  & $\frac{1}{2} \sum_{i,j} ( a_{i,j} - \Phi_i\cdot\Phi_j )^2\newline + \frac{\lambda}{2}\sum_i ||\Phi_i||^2$ & SGD with  \newline asynchronous \newline optimization (ASGD)\\
\hline
 HOPE &   \checkmark &$||\textbf{C} - \Phi \cdot\Theta||_F^2$, $C-$ может быть записана в разном виде, например для RootedPageRank, см. уравнение \ref{eqn:HOPERPR} & Matrix Factorization\\
\hline
 NetMF &      \checkmark  & $|| \log (\frac{vol(G)}{bT}(\sum_{r=1}^T \textbf{P}^r)\textbf{D}^{-1}) - \Phi \cdot \Theta||_F^2$\newline (значение параметров см. в описании к ур-ию \ref{eqn:NetMF}) &Matrix Factorization \\
\hline
 DeepWalk &   \checkmark  & $- \sum_{v_j \in V} \sum_{v_i \in N(v_j)} log \frac{\exp (\Theta_i \cdot \Phi_j)}{\sum_{v_k \in V} \exp (\Theta_k \cdot \Phi_j) } $, где $N(v)$ -- см. таблицу \ref{tab:notation}. В данном случае случайные блуждания фиксированной длины & SGD, ASGD.\newline  Hierarchical Softmax \\
\hline
 Node2Vec &  \checkmark      & $- \sum_{v_j \in V} \sum_{v_i \in N(v_j)} log \frac{\exp (\Theta_i \cdot \Phi_j)}{\sum_{v_k \in V} \exp (\Theta_k \cdot \Phi_j) } $\newline Случайные блуждания имеют два параметра - вероятноность перехода к вершинам, отвечающим за исследования локальной  и глобальной структур& SGD with negative Sampling \\

\hline
\end{tabular}
\end{table} 

\begin{table}
\setlength{\extrarowheight}{10pt}
\begin{tabular}{|p{60pt}|p{60pt}|p{180pt}|p{110pt}|}
\hline
 Struc2Vec&   \checkmark  & $- \sum_{v_j \in V} \sum_{v_i \in N(v_j)} log \frac{\exp (\Theta_i \cdot \Phi_j)}{\sum_{v_k \in V} \exp (\Theta_k \cdot \Phi_j) } $\newline Случайные блуждания строятся по контекстному графу, учитываемому структурную схожесть вершин & Hierarchical Softmax \\
\hline
 Seed. Эмбединги графов ! & $\times$ &  $ ||\textbf{X} - \hat{\textbf{X}}||_2^2$, где $\hat{\textbf{X}}$-- Реконструкция графа.  & Gradient descent, deep autoencoders\\
\hline
 App &  \checkmark  &  $- \sum_{v_j \in V} \sum_{v_i \in N(v_j)} \log\ \frac{1}{1+ exp(-\Theta_i \cdot \Phi_j)}$\newline для построения случайных последовательностей испольузется метод Monte-Carlo End-Point &Skip-Gram with \newline Negative Sampling   \\
\hline
 VERSE &  $\times$  & $-\sum_{i,j=1}^{n} sim_G(v_i,v_j) \log\frac{\exp (\Phi_i \cdot \Phi_j)}{\sum_{k=1}^n \exp (\Phi_i \cdot \Phi_k)}$ \newline $sim_G$ -- распределение схожести вершин графа. В случае PPR, $sim_G(v,\cdot)$ -- последняя вершина в одном случайном блуждании начатого с вершины v, в случаях других мер схожести, определяется уравнениями \ref{SR}, \ref{ADJ} &Gradient Descent, \newline Noise Constractive Estimations. \newline Negative Sampling  \\
\hline
 GraphSAGE &  $\times$  & $- \sum_{v_j \in V} \sum_{v_i \in N(v_j)} \log  \frac{1}{1+ exp(-\Phi_i \cdot \Phi_j)}$   & SGD, \newline  Negative Sampling  \\
\hline
 SDNE  &  $\times$ &    $|| (\hat{\textbf{A}} - \textbf{A}) \odot B||_F^2 + \alpha \sum_{v_i,v_j \in V} a_{i,j}||\Phi_i - \Phi_j||_2^2$, где $\odot$ -- произведение Адамара, $B$--матрицы смещений (biases). $\hat{\textbf{A}}$-- реконструкция матрицы смежности&  SGD, \newline Deep autoencoders\\
\hline
 LINE-1 & $\times$  & $- \sum_{v_i,v_j\in V} a_{ij}\log  \frac{1}{1+ exp(-\Phi_i \cdot \Phi_j)}$&  ASGD with Negative Sampling \\
\hline LINE-2 & \checkmark & $ - \sum_{v_i,v_j\in V} a_{ij}\log \frac{\exp (\Phi_i \cdot \Theta_j)}{\sum_{v_k \in V} \exp (\Phi_i \cdot \Theta_k)}$& ASGD with Negative Sampling\\
\hline
\end{tabular}
\end{table} 

\newpage
{\section{Замечания, идеи}}
Можно считать, что основных общих классов функций потерь 5 штук:

\begin{table}[ph]
\caption{\label{tab:classification}Общй вид функций потерь}
\setlength{\extrarowheight}{10pt}
\begin{tabular}{|p{60pt}|p{190pt}|p{110pt}|}
\hline
id & Общий вид & Методы  \\
\hline
 1 & $-\sum_{i=1}^{n} \sum_{j=1}^{n}c_{i,j} \log\frac{\exp (\Phi_i \cdot \Theta_j)}{\sum_{k=1}^n \exp (\Phi_i \cdot \Theta_k)}$ & VERSE,LINE\\
 \hline
 2 & $-\sum_{i=1}^{n} \sum_{j: v_j \in N(v_i)}c_{i,j} \log\frac{\exp (\Phi_i \cdot \Theta_j)}{\sum_{k=1}^n \exp (\Phi_i \cdot \Theta_k)}$ & DeepWalk,Node2Vec,\newline Struc2Vec,APP,\newline GraphSage\\
 \hline
 3 & $||C-\Phi \cdot \Theta||^2$ & HOPE,NetMF, Graph Factorization\\
 \hline
 4 & $tr(\Phi^T L \Phi) = \frac{1}{2} \sum_{i=1}^{n}\sum_{j=1}^{n}|\Phi_i - \Phi_j|^2 a_{ij}$ & LaplacianEigenMaps, SDNE-1\\
 \hline
 5 & Ошибки реконструкции (О.Р.)\newline $|| \hat{M} -M ||$& Seed (О.Р. матрицы фичей M= X), SDNE-2 (О.Р. матрицы смежности M= A)\\
 \hline
\end{tabular}
\end{table} 
{\subsection{Схожесть}}
\begin{enumerate}
\item ф.п. вида 2 можно относительно просто перевести в вид 3. Об этом подробнее в пунктe \ref{section:NetMF}, в методе NetMF
\item ф.п. вида 1 тоже можно перевести в вид 3, все в том же NetMF. Но с другой стороны, можно попробовать представить ф.п. вида 1 в виде 2. Об этом идет речь в ''A Comparative Study for Unsupervised Network Representation Learning'''. См. пункт \ref{section:ComparStudy}
\item есть ощущение, что ф.п. вида 4 можно представить в виде 3, но что-то пока не получается
\item вообще необходимо ли рассматривать ф.п. вида 5? Там требуется дополнительное действие, по сравнению с предыдущими ф.п. - декодер.
\item матрица $S^{PPR}$ , которая присутсвует и HOPE, VERSE, APP означает насколько схожи вершины графа, причем схожесть измеряется по веряотности достичь одной вершины из другой в ходе случайных блужданий. НО не все так просто, ведь в  $S^{PPR}$, записанной в явном виде, вершина а достигла вершины б в ходе неоггрниченного по длине блуждания. А в DeepWalk, Node2Vec, блуждания ограничены и по количеству и по длине. Подробнее по PageRank'у написано в пункте \ref{section:pageRank} 
\item Насколько эквивалетно две ф.п $||С-\Phi\cdot\Theta||$ и $\sum_{ij} C_{ij}\log(\sigma(\Phi\cdot \Theta))$
\end{enumerate}
{\subsection{HOPE}}
 В методе HOPE минимизируется $||\textbf{C} - \Phi \cdot\Theta||_F^2$. В данном случае элементы матрицы $c_{ij}$ отражают близость вершин $v_i,v_j$. $C$ можно представить в виде $C=\textbf{M}_g^{-1}\textbf{M}_l$, а матрицы $\textbf{M}_g,\textbf{M}_l$ отличаются для каждой из мер схожести. Рассмотрим:

Rooted PageRank
В данном случае $C_{i,j}^{RPR}-$ вероятность того, что случайное блуждание, начавшееся в вершине $i$ в steady state окажется в вершине $j$. При $\alpha$ -- равной  вероятности рандомного перехода к соседу:
\begin{equation}\label{eqn:HOPERPR}
\begin{aligned}
\textbf{M}_g = \textbf{I}-\alpha \cdot \textbf{P},\\
 \textbf{M}_l = (1-\alpha) \cdot \textbf{I}, 
\end{aligned}
\end{equation}
То есть, чем меньше вероятность того, что i,j окажутся концами одного случайного блуждания в устойчивом состоянии, тем меньше скалярное поизведение соответствующих эмбеддингов, а значит сами эмбеддинги отдаляются. И наоборот. Чем больше вероятность того, что i,j окажутся концами одного случайного блуждания в устойчивом состоянии, тем больше скалярное поизведение соответствующих эмбеддингов, тем ближе друг к другу эти эмбеддинги.

{\subsection{! NetMF!}\label{section:NetMF}}
Каждая из четырех моделей: DeepWalk, LINE, PTE, Node2vec, выполняют неявную матричную факторизацию. Для каждой из обозначенных моделей выведены матричные формы, следующим образом:
\begin{enumerate}
\item В изначальной функции потерь делаются несколько замен обозначений  
\item Так как функция потерь минимизируется по $\Phi^{T}\Theta$, то берется производная от $\mathcal{L}$ по $\Phi^{T} \Theta$ и приравнивается к нулю
\item Ищутся корни. Итого находят выражение для $\Phi^{T} \Theta$. Обозначают для краткости $\Phi^{T} \Theta = \log (\textbf{M})$ 
\item Но теперь стоит задача найти сами эмбеддинги, если известно их произведение
\item В явном виде сложно найти, тогда минимизируем $||\log (\textbf{M}) - \Phi^{T}\Theta||$
\item А решение данной минимизации будет SVD на $\log (\textbf{M})$.
\item  $\log (\textbf{M})= U_d \Sigma_d V_d^{T}$. 
\item Оптимальные значения эмбедингов $\Phi = U_d \sqrt{\Sigma_d}$
\end{enumerate} 
Например алгоритм LINE эквивалентен факторизации матрицы (не softmax, а sogmoid + Negative Samling):
\begin{equation}\label{eqn:NetMF_LINE}
\log (vol(G)D^{-1}AD) - \log(b)
\end{equation}
А алгоритм DeepWalk экивалентен факторизации следующей матрицы:
\begin{equation}\label{eqn:NetMF}
\log (\frac{vol(G)}{T}(\sum_{r=1}^T \textbf{P}^r)\textbf{D}^{-1}) - \log(b)
\end{equation}
в данном случае $b$ негативных примеров для Negative Sampling, vol(G) - объем взвешенного графа (сумма степеней всех вершин), T - длина случайного блуждания, r - размер окна в DeepWalk.


 {\subsection{Немного про PageRank}\label{section:pageRank}}
 
 (где упоминается: HOPE, VERSE, APP)
 
 PPR для вершины $v$.
 
 $s$ - начальное распределение. Имеет длину $n$ (количество вершин). One-hot вектор, где каждый элемент относится к каждой вершине графа, 1 стоит на одном месте - относительно той вершины, которую рассматриваем. Тогда $s\cdot\textbf{P} - $ вектор длины $n$, где каждый элемент означает вероятность того, что вершина $v$ перешла в соответвующую номеру индекса элемента вектора вершину.  
 
 $s \cdot \textbf{P}\textbf{P}$ - означает уже вектор, с вероятностями для вершины $v$ оказаться в соответствующей вершине спустя два прыжка. и т.д.
 К тому же, если мы введем параметр $\alpha$ - вероятность того, что переход к соседу вообще будет совершен, то соответвенно итоговый вектор вероятностей будет является вектором $ppr_v(t)$ и будет записан в виде:
 \begin{equation}
 ppr_v(t+1) = \alpha\cdot ppr_v(t)\textbf{P} + (1-\alpha) s
 \end{equation} 
 Можно рассмотреть попарные схожести и записать уравнение выше в матричном виде. Тогда начально распределение будет единичной матрицей (Т.е., $S^{PPR}(0)=\textbf{I}$), а уравнение будет в следующем виде:
  \begin{equation}
 S^{PPR}(t+1) = \alpha\cdot S^{PPR}(t)\textbf{P} + (1-\alpha) \textbf{I}
 \end{equation} 
 Сходится ли? Покажем это:
 
   \begin{equation}
   \begin{split}
 \textbf{S}^{PPR}(t) = \alpha^2\cdot \textbf{S}^{PPR}(t-2)\textbf{P}^2 +\alpha (1-\alpha)\textbf{P} + (1-\alpha) \textbf{I} =  \\
 = \alpha^t \textbf{S}^{PPR}(0) \textbf{P}^t + (1-\alpha) \sum_{i=0}^{t-1}\alpha^i \textbf{P}^i
 \end{split}
 \end{equation} 
Теперь можем достаточно просто найти предел $\lim_{t \rightarrow \infty }\textbf{S}^{PPR}(t)$. 
 
 Имеем: $0<\alpha<1$ и у матрицы $\textbf{P}$ каждый элемент тоже болье нуля и меньше единицы по построению. Тогда предел первого слагаемого равен нулю, а второе слагаемое - сумма геометрической убывающей прогрессии. Можно применить формулу суммы убывающей геометрической прогрессии. (либо, по-другому, вспомнить формулу $(\textbf{P}^n - \textbf{I}) = (\textbf{P}-\textbf{I})(\textbf{P}^{n-1}+\textbf{P}^{n-2}+...)$):
  \begin{equation}
   S^{PPR}=\lim_{t \rightarrow \infty }\textbf{S}^{PPR}(t) = (1-\alpha) (\textbf{I}-\alpha\textbf{P})^{-1}
 \end{equation} 
 У данной, итоговой предельной матрицы каждый элемент означает вероятность перехода точки $i$ в ходе случайного блуждания с ероятностью рестарта $\alpha$ в точку $j$. (Именно такая матрица рассмотрена в HOPE и VERSE).
 {\subsection{связь $S^{PPR}$ c DeepWalk}}
 {\subsubsection{Идея, высказанная в VERSE}}
 По утвержденю авторов статьи VERSE, DeepWalk при стремлении длины случайных блужданий и количества случайных блужданий к бесконечности, делает примерно то же, что и $PPR$.
   
 Доказательсвто: в deepWalk от вершины запускается случайное блуждание бесконечной длины, но рассматривается окно длины $w$. X - случайная величина, означающая насколько далеко  блуждание ушло от изначальной точки в пределах окна. Соответвенно, распределение вероятностей данной случайной величины:
 \begin{equation}
 Pr(X=j) = \frac{2}{w(w+1)}(w-j+1)
 \end{equation}
 Оно получено следующим образом: после проведения случайного блуждания, в качестве контекста выбирают все точки, входящие в данное с.б, причем внутри одного случайного блуждания повторяющиеся точки берутся один раз.
 
 Бесконечное случайное блуждание внутри окна w может быть одним из w видов:
 \begin{enumerate}
 \item может так и не выйти дальше чем соседняя вершина и бесконечно крутиться к соседу и обратно. Тогда контекст - 1 вершина.
 \item может продвинуться на 2 вершины от нынешней и обратно, так и не выйдя за пределы. Тогда в качестве контекста уже берется две вершины. 
 \item и т.д.
 \item Уйдет на длину w или дальше, тогда все вершины внутри окна w будут выбраны в качестве контекста по одному разу
 \end{enumerate}
 
 Отсюда видно, что всего $w$ вариантов случайных блужданий, попавших в окно $w$. Кроме того, вершина, непосредственно сосествующая с начальной будет выбрана $w$ раз, вторая $w-1$ раз и т.д. То есть всего выбрано $\sum_{i=1}^w i = \frac{w(w+1)}{2}$ вершин, а вершина на расстоянии $j$ рёбер будет выбрана $(w-j+1)$ раз.
 
 Автором статьи утверждается, что распредление $sim(v,\cdot)$ схоже с распределением выше. Но ''$sim(v,\cdot)$--биномиальное распределение, а $Pr(X=j)$--треугольное, но если взять maximum likelihood estimation для параметра биномиального треугольным  распределением, то $\alpha=\frac{w-1}{w+1}$'' (с), из видео самого автора.
 
 (s - вектор со всеми элементами кроме одного равными нулю, а единице равен тот элемент соотвествующий вершие вершине, с которой начался старт). Тогда:
\begin{equation}
sim(v,\cdot) = (1-\alpha)s\cdot (\textbf{I}-\alpha \textbf{P})^{-1} 
\end{equation}
($sim^{PPR}(v,\cdot)$ Personalized PageRank: один экзамепляр $sim_G(v,\cdot)$ это последняя вершина в одом случайном блуждании, начатом с вершины $v$. - цитата из статьи)

 Я честно пыталась, но не могу связать эти два распределения друг с другом.  
 
{\subsubsection{Чуть более в лоб или (?) простая марковская цепь (?)}}

В методе DeepWalk важно количество пар $(i,j)$ ($i$--целевая, $j$--контекст) внутри окон всех запущенных случайных блужданий. (Если рассмотрим упрощенный вариант, когда длина случайного блуждания равна длине окна $2 w+1$) то есть, если окно имеет длину w, то вероятность появления пары (i,j) считается как объединение событий:$A_{1}$ = случайным блужданием из $i$ в $j$ попали одним шагом $\cup$ ... $\cup$ $ A_{w}$ = случайным блужданием из $i$ в $j$ попали спустя $w$ шагов  $\cup$$ A_{-1}$ = случайным блужданием попали из вершины $j$ в вершину $i$ одним шагом  $\cup$ $A_{-w}$= случайным блужданием из $j$ в $i$ попали спустя $w$ шагов. Тогда, вероятность внутри одного блуждания появления пары $(i,j)$ равна 
\begin{equation}
Pr(i,j) = Pr(A_{-w}\cup ...\cup A_{-1}\cup A_{1} ...\cup A_{w}) = \sum_{r=1}^w (\textbf{P}^r (i,j) + \textbf{P}^r (j,i) )
\end{equation}
То есть, если от вершины $i$ было запущено $\gamma$ случайных блужданий, то пар (i,j) будет $\gamma \sum_{r=1}^w (\textbf{P}^r (i,j) + \textbf{P}^r (j,i) )$ штук, или в матричном виде:
$\gamma \sum_{r=1}^w (\textbf{P}^r  + \textbf{P$^\text{T}$}^r )$ 
А т.к. каждый элемент матрицы \textbf{P} больше нуля и меньше единицы, то применим формулу убывающей геометрической прогрессии:

\begin{equation}
\textbf{C} = \gamma \sum_{r=1}^w (\textbf{P}^r  + \textbf{P$^\text{T}$}^r ) = \gamma ( \textbf{P}(\textbf{I}-\textbf{P}^w)(\textbf{I}-\textbf{P})^{-1} + \textbf{P$^\text{T}$}(\textbf{I}-\textbf{P$^\text{T}$}^w)(\textbf{I}-\textbf{P$^\text{T}$})^{-1})
\end{equation}
За $\textbf{C}$ мы обозначили так называемую котекстную матрицу. Теперь, 
\begin{equation}
\sum_{i,j} c_{ij} \log(\frac{\exp(\Phi_i \cdot \Theta_j)}{\sum_{k\in V} (\exp(\Phi_i \cdot \Theta_k)) })
\end{equation}
Эквивалентно функции потерь DeepWalk для случая, когда длина окна равна длине случайных блужданий 

В Comparative Sudy получают что-то похожее, но как бы нормализованное
{\subsection{Comparative Sudy. Из вида 1 в вид 2}\label{section:ComparStudy}}
(Рассматривают случайные блуждания бесконечной длины)
{\subsubsection{\textbf{C} для DeepWalk}}
В качестве $\textbf{C}$ взяли матрицу, которую получили в статье NetMf. То есть утверждается, что матрицу из $||\textbf{C}-\Phi\cdot \Theta||$ можно использовать в функции потерь 
\begin{equation}
\sum_{i,j} c_{ij} \log(\frac{\exp(\Phi_i \cdot \Theta_j)}{\sum_{k\in V} (\exp(\Phi_i \cdot \Theta_k)) })
\end{equation}
С поправкой на нормализацию $\textbf{C}$.
А матрица $\textbf{C}$ получена по алгоритму описанному в \ref{section:NetMF}. 

Итак, 
\begin{equation}
\frac{c_{ij}}{\sum_{u,v|c_{u,v}>0}c_{uv}} \rightarrow \frac{1}{2w} \sum_{r=1}^{w}(\frac{d_i}{\sum_i d_i}\cdot(\textbf{P}^r)_{(i,j)}+\frac{d_j}{\sum_i d_i}\cdot(\textbf{P}^r)_{(j,i)})
\end{equation}
Слагаемое $\frac{d_i}{\sum_{i}d_i}$ является начальным распределением, означающим вероятность того, что первая вершина в случайном блуждании именно $i$ 
{\subsubsection{\textbf{C} для Node2Vec}}
Вводится другая матрица переходов, учитывающая ''откуда'' пришла вершина:
\begin{equation}
\underline{\textbf{P}}_{k\rightarrow i\rightarrow j} = \frac{T_{k\rightarrow i\rightarrow j}}{\sum_j T_{k\rightarrow i\rightarrow j}}
\end{equation}
Что по сути является вероятностью пеерйти от вершины $i$ к вершине $j$, если вершина $i$ только пришла от вершины $k$ ($T = \frac{1}{p}$ или $\frac{1}{q}$ или $1$)

Осталось только получить вероятность оказаться в вершине $i$, что и обозначают за $\textbf{X}$ -- стационарное распределение случайных блужданий
Как поняла я. $\textbf{X}_k$ -- вектор с вероятностями для вершины $k$ перейти в вершины, соотвествующие индексам элементов этого вектора. 

Тогда всё по аналоги с DeepWalk:
\begin{equation}
\frac{c_{ij}}{\sum_{u,v|c_{u,v}>0}c_{uv}} \rightarrow \frac{1}{2w} \sum_{r=1}^{w}(\textbf{X}_{ki}\cdot(\underline{\textbf{P}}^r)_{(k,i,j)}+X_{kj}\cdot(\underline{\textbf{P}}^r)_{(j,k,i)})
\end{equation}
{\subsubsection{\textbf{C} для APP,VERSE}}
Тут очень просто, матрица $C$ -- это и есть $S^{PPR}$


\end{document}